{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from sqlalchemy import create_engine\n",
    "import pymysql\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(1030)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paths and Connection Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "exec(open(\"/Users/walkerag/Documents/osu/cs467/project_paths.py\").read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_connection = create_engine(db_connection_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Tables_in_project\n",
      "0                    Country\n",
      "1                       Item\n",
      "2             Price_Feedback\n",
      "3             Price_Response\n",
      "4              Shopping_List\n",
      "5      Shopping_List_History\n",
      "6                      State\n",
      "7                      Store\n",
      "8             Store_Feedback\n",
      "9    Store_Feedback_Category\n",
      "10            Store_Response\n",
      "11                      User\n",
      "12           User_Reputation\n",
      "13  User_Reputation_Category\n",
      "Country\n",
      "          Field              Type Null  Key Default           Extra\n",
      "0    country_id  int(10) unsigned   NO  PRI    None  auto_increment\n",
      "1  country_name       varchar(50)   NO         None                \n",
      "Item\n",
      "              Field              Type Null  Key Default           Extra\n",
      "0           item_id  int(10) unsigned   NO  PRI    None  auto_increment\n",
      "1         item_name       varchar(50)   NO         None                \n",
      "2          item_upc       varchar(12)   NO         None                \n",
      "3  item_description      varchar(200)   NO         None                \n",
      "4        date_added          datetime   NO         None                \n",
      "5         item_size           int(10)   NO         None                \n",
      "6    item_size_unit       varchar(20)  YES         None                \n",
      "Price_Feedback\n",
      "                 Field              Type Null  Key Default           Extra\n",
      "0    price_feedback_id  int(10) unsigned   NO  PRI    None  auto_increment\n",
      "1             store_id  int(10) unsigned  YES  MUL    None                \n",
      "2              user_id  int(10) unsigned  YES  MUL    None                \n",
      "3              item_id  int(10) unsigned  YES  MUL    None                \n",
      "4                price     decimal(10,2)   NO         None                \n",
      "5       price_currency       varchar(10)   NO         None                \n",
      "6            sale_flag        tinyint(1)   NO         None                \n",
      "7  price_feedback_text      varchar(200)  YES         None                \n",
      "8           time_added          datetime   NO         None                \n",
      "Price_Response\n",
      "                 Field              Type Null  Key Default           Extra\n",
      "0    price_response_id  int(10) unsigned   NO  PRI    None  auto_increment\n",
      "1    price_feedback_id  int(10) unsigned  YES  MUL    None                \n",
      "2     response_user_id  int(10) unsigned  YES  MUL    None                \n",
      "3           time_added          datetime   NO         None                \n",
      "4  price_response_text      varchar(200)   NO         None                \n",
      "5  price_response_vote           int(10)  YES         None                \n",
      "Shopping_List\n",
      "                      Field              Type Null  Key Default  \\\n",
      "0          shopping_list_id  int(10) unsigned   NO  PRI    None   \n",
      "1                   user_id  int(10) unsigned  YES  MUL    None   \n",
      "2                   item_id  int(10) unsigned  YES  MUL    None   \n",
      "3                time_added          datetime   NO         None   \n",
      "4  shopping_list_history_id  int(10) unsigned  YES  MUL    None   \n",
      "5             item_quantity           int(10)   NO         None   \n",
      "\n",
      "            Extra  \n",
      "0  auto_increment  \n",
      "1                  \n",
      "2                  \n",
      "3                  \n",
      "4                  \n",
      "5                  \n",
      "Shopping_List_History\n",
      "                      Field              Type Null  Key Default  \\\n",
      "0  shopping_list_history_id  int(10) unsigned   NO  PRI    None   \n",
      "1                   user_id  int(10) unsigned  YES  MUL    None   \n",
      "2                   item_id  int(10) unsigned  YES  MUL    None   \n",
      "3                time_added          datetime   NO         None   \n",
      "4              time_removed          datetime  YES         None   \n",
      "\n",
      "            Extra  \n",
      "0  auto_increment  \n",
      "1                  \n",
      "2                  \n",
      "3                  \n",
      "4                  \n",
      "State\n",
      "        Field              Type Null  Key Default           Extra\n",
      "0    state_id  int(10) unsigned   NO  PRI    None  auto_increment\n",
      "1  state_name        varchar(2)   NO         None                \n",
      "Store\n",
      "               Field              Type Null  Key Default           Extra\n",
      "0           store_id  int(10) unsigned   NO  PRI    None  auto_increment\n",
      "1         store_name       varchar(50)   NO         None                \n",
      "2          store_lat     decimal(10,8)   NO         None                \n",
      "3         store_long     decimal(11,8)   NO         None                \n",
      "4  store_active_flag        tinyint(1)   NO         None                \n",
      "5       store_street       varchar(50)  YES         None                \n",
      "6         store_city       varchar(50)  YES         None                \n",
      "7        store_state  int(10) unsigned  YES  MUL    None                \n",
      "8          store_zip       varchar(10)  YES         None                \n",
      "Store_Feedback\n",
      "                        Field              Type Null  Key Default  \\\n",
      "0           store_feedback_id  int(10) unsigned   NO  PRI    None   \n",
      "1                    store_id  int(10) unsigned  YES  MUL    None   \n",
      "2                     user_id  int(10) unsigned  YES  MUL    None   \n",
      "3                  time_added          datetime   NO         None   \n",
      "4         store_feedback_text      varchar(200)  YES         None   \n",
      "5  store_feedback_category_id  int(10) unsigned  YES  MUL    None   \n",
      "\n",
      "            Extra  \n",
      "0  auto_increment  \n",
      "1                  \n",
      "2                  \n",
      "3                  \n",
      "4                  \n",
      "5                  \n",
      "Store_Feedback_Category\n",
      "                        Field              Type Null  Key Default  \\\n",
      "0  store_feedback_category_id  int(10) unsigned   NO  PRI    None   \n",
      "1     store_feedback_category       varchar(50)   NO         None   \n",
      "\n",
      "            Extra  \n",
      "0  auto_increment  \n",
      "1                  \n",
      "Store_Response\n",
      "                 Field              Type Null  Key Default           Extra\n",
      "0    store_response_id  int(10) unsigned   NO  PRI    None  auto_increment\n",
      "1    store_feedback_id  int(10) unsigned  YES  MUL    None                \n",
      "2     response_user_id  int(10) unsigned  YES  MUL    None                \n",
      "3           time_added          datetime   NO         None                \n",
      "4  store_response_text      varchar(200)   NO         None                \n",
      "5  store_response_vote           int(10)  YES         None                \n",
      "User\n",
      "          Field              Type Null  Key Default           Extra\n",
      "0       user_id  int(10) unsigned   NO  PRI    None  auto_increment\n",
      "1    first_name       varchar(50)   NO         None                \n",
      "2     last_name       varchar(50)   NO         None                \n",
      "3         email      varchar(320)   NO         None                \n",
      "4   signup_date              date   NO         None                \n",
      "5    last_login          datetime   NO         None                \n",
      "6  user_country  int(10) unsigned  YES  MUL    None                \n",
      "User_Reputation\n",
      "                         Field              Type Null  Key Default  \\\n",
      "0           user_reputation_id  int(10) unsigned   NO  PRI    None   \n",
      "1                      user_id  int(10) unsigned  YES  MUL    None   \n",
      "2              user_reputation           int(10)   NO         None   \n",
      "3  user_reputation_category_id  int(10) unsigned  YES  MUL    None   \n",
      "4        user_received_upvotes  int(20) unsigned   NO         None   \n",
      "5      user_received_downvotes  int(20) unsigned   NO         None   \n",
      "6            user_received_net           int(10)   NO         None   \n",
      "7           user_given_upvotes  int(20) unsigned   NO         None   \n",
      "8         user_given_downvotes  int(20) unsigned   NO         None   \n",
      "9               user_given_net           int(10)   NO         None   \n",
      "\n",
      "            Extra  \n",
      "0  auto_increment  \n",
      "1                  \n",
      "2                  \n",
      "3                  \n",
      "4                  \n",
      "5                  \n",
      "6                  \n",
      "7                  \n",
      "8                  \n",
      "9                  \n",
      "User_Reputation_Category\n",
      "                           Field              Type Null  Key Default  \\\n",
      "0    user_reputation_category_id  int(10) unsigned   NO  PRI    None   \n",
      "1  user_reputation_category_name       varchar(50)   NO         None   \n",
      "\n",
      "            Extra  \n",
      "0  auto_increment  \n",
      "1                  \n"
     ]
    }
   ],
   "source": [
    "all_tables = pd.read_sql('SHOW TABLES', con=db_connection)\n",
    "print(all_tables)\n",
    "\n",
    "# Describe all the DB tables\n",
    "def describe_table(table, db_connection):\n",
    "        \n",
    "    print(table)    \n",
    "    table_cols = pd.read_sql('DESCRIBE ' + table, con=db_connection)\n",
    "    print(table_cols)\n",
    "\n",
    "result = [describe_table(table, db_connection) for table in all_tables['Tables_in_project']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load data from a CSV into MySQL database\n",
    "def data_loader_csv(data_path, table_name, db_connection, load_type):\n",
    "    \n",
    "    print(\"Loading data from CSV\")\n",
    "    \n",
    "    # Read in from CSV\n",
    "    df = pd.read_csv(data_path + 'Input Data - ' + table_name.lower() + '.csv')\n",
    "    \n",
    "    print(df.head(5))\n",
    "    \n",
    "    # Load to mySQL\n",
    "    df.to_sql(table_name, con = db_connection, if_exists = load_type, index = False)\n",
    "    \n",
    "    # Check table\n",
    "    results_df = pd.read_sql('SELECT * FROM ' + table_name + ' LIMIT 5', con=db_connection)\n",
    "    print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from CSV\n",
      "     country_name\n",
      "0     Afghanistan\n",
      "1         Albania\n",
      "2         Algeria\n",
      "3  American Samoa\n",
      "4         Andorra\n",
      "   country_id    country_name\n",
      "0           8     Afghanistan\n",
      "1           9         Albania\n",
      "2          10         Algeria\n",
      "3          11  American Samoa\n",
      "4          12         Andorra\n"
     ]
    }
   ],
   "source": [
    "data_loader_csv(data_path, \"Country\", db_connection, \"append\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from CSV\n",
      "  state_name\n",
      "0         AL\n",
      "1         AK\n",
      "2         AZ\n",
      "3         AR\n",
      "4         CA\n",
      "   state_id state_name\n",
      "0         1         AL\n",
      "1         2         AK\n",
      "2         3         AZ\n",
      "3         4         AR\n",
      "4         5         CA\n"
     ]
    }
   ],
   "source": [
    "data_loader_csv(data_path, \"State\", db_connection, \"append\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader_csv(data_path, \"Item\", db_connection, \"append\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from CSV\n",
      "  first_name last_name                              email signup_date  \\\n",
      "0       Adam    Walker       adamwalker@notarealemail.com  2020-04-20   \n",
      "1      James      Dean        jamesdean@notarealemail.com  2020-04-20   \n",
      "2    Zackary     Morse     zackarymorse@notarealemail.com  2020-04-20   \n",
      "3  Heriberto    Mellor  heribertomellor@notarealemail.com  2020-04-20   \n",
      "4      Elton    Bussey      eltonbussey@notarealemail.com  2020-04-20   \n",
      "\n",
      "   last_login  user_country  \n",
      "0  2020-04-20           235  \n",
      "1  2020-04-20           235  \n",
      "2  2020-04-20           235  \n",
      "3  2020-04-20           235  \n",
      "4  2020-04-20           235  \n",
      "   user_id first_name last_name                              email  \\\n",
      "0        1       Adam    Walker       adamwalker@notarealemail.com   \n",
      "1        2      James      Dean        jamesdean@notarealemail.com   \n",
      "2        3    Zackary     Morse     zackarymorse@notarealemail.com   \n",
      "3        4  Heriberto    Mellor  heribertomellor@notarealemail.com   \n",
      "4        5      Elton    Bussey      eltonbussey@notarealemail.com   \n",
      "\n",
      "  signup_date last_login  user_country  \n",
      "0  2020-04-20 2020-04-20           235  \n",
      "1  2020-04-20 2020-04-20           235  \n",
      "2  2020-04-20 2020-04-20           235  \n",
      "3  2020-04-20 2020-04-20           235  \n",
      "4  2020-04-20 2020-04-20           235  \n"
     ]
    }
   ],
   "source": [
    "data_loader_csv(data_path, \"User\", db_connection, \"append\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from CSV\n",
      "     store_name  store_lat  store_long  store_active_flag  \\\n",
      "0  Trader Joe's          0           0                  1   \n",
      "1  Trader Joe's          0           0                  1   \n",
      "2  Trader Joe's          0           0                  1   \n",
      "3  Trader Joe's          0           0                  1   \n",
      "4  Trader Joe's          0           0                  1   \n",
      "\n",
      "          store_street           store_city  store_state  store_zip  \n",
      "0  417 Westlake Center            Daly City            5      94015  \n",
      "1   301 McLellan Drive  South San Francisco            5      94080  \n",
      "2       265 Winston Dr        San Francisco            5      94132  \n",
      "3           401 Bay St        San Francisco            5      94133  \n",
      "4        3 Masonic Ave        San Francisco            5      94118  \n",
      "   store_id    store_name  store_lat  store_long  store_active_flag  \\\n",
      "0        67  Trader Joe's        0.0         0.0                  1   \n",
      "1        68  Trader Joe's        0.0         0.0                  1   \n",
      "2        69  Trader Joe's        0.0         0.0                  1   \n",
      "3        70  Trader Joe's        0.0         0.0                  1   \n",
      "4        71  Trader Joe's        0.0         0.0                  1   \n",
      "\n",
      "          store_street           store_city  store_state store_zip  \n",
      "0  417 Westlake Center            Daly City            5     94015  \n",
      "1   301 McLellan Drive  South San Francisco            5     94080  \n",
      "2       265 Winston Dr        San Francisco            5     94132  \n",
      "3           401 Bay St        San Francisco            5     94133  \n",
      "4        3 Masonic Ave        San Francisco            5     94118  \n"
     ]
    }
   ],
   "source": [
    "data_loader_csv(data_path, \"Store\", db_connection, \"append\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnx = mysql.connector.connect(user='root', password='cs467project',\n",
    "                              host='localhost',\n",
    "                              database='romanesco',\n",
    "                              use_pure=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_sql('DELETE FROM Store', con=db_connection)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Field              Type Null  Key Default           Extra\n",
      "0    country_id  int(10) unsigned   NO  PRI    None  auto_increment\n",
      "1  country_name       varchar(50)   NO         None                \n"
     ]
    }
   ],
   "source": [
    "df = pd.read_sql('DESCRIBE Country', con=db_connection)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_sql('SELECT * FROM Country', con=db_connection)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_hastie_10_2\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_hastie_10_2(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.45427351,  0.76103773,  0.12167502,  0.44386323,  0.33367433,\n",
       "         1.49407907, -0.20515826,  0.3130677 , -0.85409574],\n",
       "       [ 0.6536186 ,  0.8644362 , -0.74216502,  2.26975462, -1.45436567,\n",
       "         0.04575852, -0.18718385,  1.53277921,  1.46935877],\n",
       "       [ 0.37816252, -0.88778575, -1.98079647, -0.34791215,  0.15634897,\n",
       "         1.23029068,  1.20237985, -0.38732682, -0.30230275],\n",
       "       [-1.42001794, -1.70627019,  1.9507754 , -0.50965218, -0.4380743 ,\n",
       "        -1.25279536,  0.77749036, -1.61389785, -0.21274028],\n",
       "       [ 0.3869025 , -0.51080514, -1.18063218, -0.02818223,  0.42833187,\n",
       "         0.06651722,  0.3024719 , -0.63432209, -0.36274117],\n",
       "       [-0.35955316, -0.81314628, -1.7262826 ,  0.17742614, -0.40178094,\n",
       "        -1.63019835,  0.46278226, -0.90729836,  0.0519454 ],\n",
       "       [ 0.12898291,  1.13940068, -1.23482582,  0.40234164, -0.68481009,\n",
       "        -0.87079715, -0.57884966, -0.31155253,  0.05616534],\n",
       "       [ 0.90082649,  0.46566244, -1.53624369,  1.48825219,  1.89588918,\n",
       "         1.17877957, -0.17992484, -1.07075262,  1.05445173],\n",
       "       [ 1.22244507,  0.20827498,  0.97663904,  0.3563664 ,  0.70657317,\n",
       "         0.01050002,  1.78587049,  0.12691209,  0.40198936]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[1:10,1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = X[:2000], X[2000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train, y_test = y[:2000], y[2000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0,max_depth=1, random_state=0).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.913"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create and upload a shopping list for a given user_id\n",
    "# min_items and max_items limit number of items in list\n",
    "def _fill_list(user_id, min_items, max_items, items):\n",
    "    \n",
    "    # Determine total items in list\n",
    "    tot_items = np.random.uniform(min_items, max_items, 1).round().astype(int)\n",
    "    print(tot_items)\n",
    "\n",
    "    # Get item IDs\n",
    "    list_items = np.random.choice(items['item_id'], tot_items, replace=False)\n",
    "\n",
    "    # Convert to pandas dataframe\n",
    "    dataset = pd.DataFrame({'item_id': list_items})\n",
    "\n",
    "    # Format dataframe\n",
    "    dataset['user_id'] = user_id\n",
    "    dataset['time_added'] = datetime.datetime.now()\n",
    "    dataset['time_removed'] = None\n",
    "    dataset = dataset[['user_id', 'item_id','time_added','time_removed']]\n",
    "\n",
    "    # Load to mySQL\n",
    "    print(\"Loading\")\n",
    "    dataset.to_sql('Shopping_List_History', con = db_connection, if_exists = \"append\", index = False)\n",
    "\n",
    "# Generate shopping list by sampling from items table\n",
    "def generate_shopping_list_history(db_connection, min_items, max_items):\n",
    "    \n",
    "    # Get items\n",
    "    items = pd.read_sql('SELECT DISTINCT item_id FROM Item', con=db_connection)\n",
    "    \n",
    "    # Users\n",
    "    users = pd.read_sql('SELECT DISTINCT user_id FROM User', con=db_connection)\n",
    "    \n",
    "    # Loop over users\n",
    "    result = [_fill_list(user_id, min_items, max_items, items) for user_id in users['user_id']]\n",
    "\n",
    "generate_shopping_list_history(db_connection, 1, 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check result\n",
    "df = pd.read_sql('SELECT * FROM Shopping_List_History LIMIT 100', con=db_connection)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           store_name\n",
      "0        Trader Joe's\n",
      "1             Safeway\n",
      "2  Whole Foods Market\n",
      "3              Costco\n"
     ]
    }
   ],
   "source": [
    "# Get distinct chains\n",
    "store_names = pd.read_sql('SELECT DISTINCT store_name FROM Store', con=db_connection)\n",
    "print(store_names)\n",
    "\n",
    "#\n",
    "stores_names['store_quality'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = np.random.uniform(-1,0,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.80597878, -0.89860904, -0.46956359, -0.09330859, -0.06566857,\n",
       "       -0.26490908, -0.66790888, -0.56057857, -0.53782422, -0.1592114 ])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get users\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = pd.read_sql('SELECT DISTINCT item_id FROM Item', con=db_connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = pd.read_sql('SELECT DISTINCT user_id FROM User', con=db_connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe_table(table, db_connection):\n",
    "        \n",
    "    print(table)    \n",
    "    table_cols = pd.read_sql('DESCRIBE ' + table, con=db_connection)\n",
    "    print(table_cols)\n",
    "\n",
    "result = [fill_list(user_id, min_items, max_items) for user_id in users['user_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   shopping_list_history_id  user_id  item_id          time_added time_removed\n",
      "0                         1        3       19 2020-04-22 06:18:58         None\n",
      "1                         2        3       11 2020-04-22 06:18:58         None\n",
      "2                         3        3       50 2020-04-22 06:18:58         None\n",
      "3                         4        3       17 2020-04-22 06:18:58         None\n",
      "4                         5        3       34 2020-04-22 06:18:58         None\n",
      "5                         6        3       48 2020-04-22 06:18:58         None\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_sql('SELECT * FROM Shopping_List_History', con=db_connection)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_sql('DELETE FROM Shopping_List_History', con=db_connection)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15]\n",
      "Loading\n",
      "[30]\n",
      "Loading\n",
      "[39]\n",
      "Loading\n",
      "[12]\n",
      "Loading\n",
      "[35]\n",
      "Loading\n",
      "[30]\n",
      "Loading\n",
      "[28]\n",
      "Loading\n",
      "[33]\n",
      "Loading\n",
      "[8]\n",
      "Loading\n",
      "[6]\n",
      "Loading\n",
      "[1]\n",
      "Loading\n",
      "[32]\n",
      "Loading\n",
      "[26]\n",
      "Loading\n",
      "[10]\n",
      "Loading\n",
      "[2]\n",
      "Loading\n",
      "[25]\n",
      "Loading\n",
      "[20]\n",
      "Loading\n",
      "[39]\n",
      "Loading\n",
      "[7]\n",
      "Loading\n",
      "[17]\n",
      "Loading\n",
      "[17]\n",
      "Loading\n",
      "[13]\n",
      "Loading\n",
      "[31]\n",
      "Loading\n",
      "[13]\n",
      "Loading\n",
      "[10]\n",
      "Loading\n",
      "[12]\n",
      "Loading\n",
      "[25]\n",
      "Loading\n",
      "[24]\n",
      "Loading\n",
      "[32]\n",
      "Loading\n",
      "[7]\n",
      "Loading\n",
      "[25]\n",
      "Loading\n",
      "[5]\n",
      "Loading\n",
      "[16]\n",
      "Loading\n",
      "[36]\n",
      "Loading\n",
      "[18]\n",
      "Loading\n",
      "[34]\n",
      "Loading\n",
      "[14]\n",
      "Loading\n",
      "[33]\n",
      "Loading\n",
      "[15]\n",
      "Loading\n",
      "[3]\n",
      "Loading\n",
      "[17]\n",
      "Loading\n",
      "[13]\n",
      "Loading\n",
      "[15]\n",
      "Loading\n",
      "[16]\n",
      "Loading\n",
      "[31]\n",
      "Loading\n",
      "[6]\n",
      "Loading\n",
      "[3]\n",
      "Loading\n",
      "[26]\n",
      "Loading\n",
      "[36]\n",
      "Loading\n",
      "[23]\n",
      "Loading\n",
      "[28]\n",
      "Loading\n",
      "[20]\n",
      "Loading\n",
      "[20]\n",
      "Loading\n",
      "[33]\n",
      "Loading\n",
      "[16]\n",
      "Loading\n",
      "[25]\n",
      "Loading\n",
      "[12]\n",
      "Loading\n",
      "[8]\n",
      "Loading\n",
      "[32]\n",
      "Loading\n",
      "[40]\n",
      "Loading\n",
      "[22]\n",
      "Loading\n",
      "[30]\n",
      "Loading\n",
      "[38]\n",
      "Loading\n",
      "[3]\n",
      "Loading\n",
      "[34]\n",
      "Loading\n",
      "[24]\n",
      "Loading\n",
      "[27]\n",
      "Loading\n",
      "[10]\n",
      "Loading\n",
      "[37]\n",
      "Loading\n",
      "[39]\n",
      "Loading\n",
      "[39]\n",
      "Loading\n",
      "[29]\n",
      "Loading\n",
      "[13]\n",
      "Loading\n",
      "[34]\n",
      "Loading\n",
      "[35]\n",
      "Loading\n",
      "[21]\n",
      "Loading\n",
      "[9]\n",
      "Loading\n",
      "[9]\n",
      "Loading\n",
      "[1]\n",
      "Loading\n",
      "[22]\n",
      "Loading\n",
      "[22]\n",
      "Loading\n",
      "[26]\n",
      "Loading\n",
      "[16]\n",
      "Loading\n",
      "[36]\n",
      "Loading\n",
      "[7]\n",
      "Loading\n",
      "[21]\n",
      "Loading\n",
      "[20]\n",
      "Loading\n",
      "[17]\n",
      "Loading\n",
      "[9]\n",
      "Loading\n",
      "[33]\n",
      "Loading\n",
      "[17]\n",
      "Loading\n",
      "[37]\n",
      "Loading\n",
      "[23]\n",
      "Loading\n",
      "[24]\n",
      "Loading\n",
      "[33]\n",
      "Loading\n",
      "[8]\n",
      "Loading\n",
      "[5]\n",
      "Loading\n",
      "[28]\n",
      "Loading\n",
      "[28]\n",
      "Loading\n",
      "[25]\n",
      "Loading\n",
      "[3]\n",
      "Loading\n",
      "[29]\n",
      "Loading\n",
      "[12]\n",
      "Loading\n",
      "[26]\n",
      "Loading\n",
      "[7]\n",
      "Loading\n",
      "[27]\n",
      "Loading\n",
      "[33]\n",
      "Loading\n",
      "[32]\n",
      "Loading\n",
      "[7]\n",
      "Loading\n",
      "[20]\n",
      "Loading\n",
      "[36]\n",
      "Loading\n",
      "[21]\n",
      "Loading\n",
      "[24]\n",
      "Loading\n",
      "[10]\n",
      "Loading\n",
      "[30]\n",
      "Loading\n",
      "[38]\n",
      "Loading\n",
      "[6]\n",
      "Loading\n",
      "[14]\n",
      "Loading\n",
      "[20]\n",
      "Loading\n",
      "[3]\n",
      "Loading\n",
      "[19]\n",
      "Loading\n",
      "[9]\n",
      "Loading\n",
      "[2]\n",
      "Loading\n",
      "[14]\n",
      "Loading\n",
      "[1]\n",
      "Loading\n",
      "[7]\n",
      "Loading\n",
      "[27]\n",
      "Loading\n",
      "[25]\n",
      "Loading\n",
      "[7]\n",
      "Loading\n",
      "[19]\n",
      "Loading\n",
      "[20]\n",
      "Loading\n",
      "[20]\n",
      "Loading\n",
      "[9]\n",
      "Loading\n",
      "[36]\n",
      "Loading\n",
      "[39]\n",
      "Loading\n",
      "[38]\n",
      "Loading\n",
      "[8]\n",
      "Loading\n",
      "[33]\n",
      "Loading\n",
      "[18]\n",
      "Loading\n",
      "[8]\n",
      "Loading\n",
      "[22]\n",
      "Loading\n",
      "[2]\n",
      "Loading\n",
      "[38]\n",
      "Loading\n",
      "[25]\n",
      "Loading\n",
      "[11]\n",
      "Loading\n",
      "[33]\n",
      "Loading\n",
      "[14]\n",
      "Loading\n",
      "[5]\n",
      "Loading\n",
      "[12]\n",
      "Loading\n",
      "[23]\n",
      "Loading\n",
      "[21]\n",
      "Loading\n",
      "[14]\n",
      "Loading\n",
      "[2]\n",
      "Loading\n",
      "[2]\n",
      "Loading\n",
      "[28]\n",
      "Loading\n",
      "[20]\n",
      "Loading\n",
      "[29]\n",
      "Loading\n",
      "[25]\n",
      "Loading\n",
      "[16]\n",
      "Loading\n",
      "[22]\n",
      "Loading\n",
      "[14]\n",
      "Loading\n",
      "[35]\n",
      "Loading\n",
      "[28]\n",
      "Loading\n",
      "[36]\n",
      "Loading\n",
      "[5]\n",
      "Loading\n",
      "[13]\n",
      "Loading\n",
      "[20]\n",
      "Loading\n",
      "[24]\n",
      "Loading\n",
      "[25]\n",
      "Loading\n",
      "[17]\n",
      "Loading\n",
      "[25]\n",
      "Loading\n",
      "[39]\n",
      "Loading\n",
      "[20]\n",
      "Loading\n",
      "[12]\n",
      "Loading\n",
      "[22]\n",
      "Loading\n",
      "[29]\n",
      "Loading\n",
      "[37]\n",
      "Loading\n",
      "[31]\n",
      "Loading\n",
      "[30]\n",
      "Loading\n",
      "[15]\n",
      "Loading\n",
      "[34]\n",
      "Loading\n",
      "[39]\n",
      "Loading\n",
      "[39]\n",
      "Loading\n",
      "[9]\n",
      "Loading\n",
      "[35]\n",
      "Loading\n",
      "[39]\n",
      "Loading\n",
      "[4]\n",
      "Loading\n",
      "[19]\n",
      "Loading\n",
      "[27]\n",
      "Loading\n",
      "[21]\n",
      "Loading\n",
      "[23]\n",
      "Loading\n",
      "[35]\n",
      "Loading\n",
      "[34]\n",
      "Loading\n",
      "[37]\n",
      "Loading\n",
      "[33]\n",
      "Loading\n",
      "[30]\n",
      "Loading\n",
      "[34]\n",
      "Loading\n",
      "[36]\n",
      "Loading\n",
      "[37]\n",
      "Loading\n",
      "[25]\n",
      "Loading\n",
      "[23]\n",
      "Loading\n",
      "[10]\n",
      "Loading\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize list of lists \n",
    "data = [['United States of America'], ['Brazil'], ['Spain']] \n",
    "  \n",
    "# Create the pandas DataFrame \n",
    "df = pd.DataFrame(data, columns = ['country_name']) \n",
    "  \n",
    "# print dataframe. \n",
    "df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
