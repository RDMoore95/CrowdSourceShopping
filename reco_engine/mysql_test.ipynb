{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from sqlalchemy import create_engine\n",
    "import pymysql\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(1030)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import datetime\n",
    "from datetime import timedelta, date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paths and Connection Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "exec(open(\"/Users/walkerag/Documents/osu/cs467/project_paths.py\").read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_connection = create_engine(db_connection_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Tables_in_project\n",
      "0                    Country\n",
      "1                       Item\n",
      "2             Price_Feedback\n",
      "3             Price_Response\n",
      "4              Shopping_List\n",
      "5      Shopping_List_History\n",
      "6                      State\n",
      "7                      Store\n",
      "8             Store_Feedback\n",
      "9    Store_Feedback_Category\n",
      "10            Store_Response\n",
      "11                      User\n",
      "12           User_Reputation\n",
      "13  User_Reputation_Category\n",
      "Country\n",
      "          Field              Type Null  Key Default           Extra\n",
      "0    country_id  int(10) unsigned   NO  PRI    None  auto_increment\n",
      "1  country_name       varchar(50)   NO         None                \n",
      "Item\n",
      "              Field              Type Null  Key Default           Extra\n",
      "0           item_id  int(10) unsigned   NO  PRI    None  auto_increment\n",
      "1         item_name       varchar(50)   NO         None                \n",
      "2          item_upc       varchar(12)   NO         None                \n",
      "3  item_description      varchar(200)   NO         None                \n",
      "4        date_added          datetime   NO         None                \n",
      "5         item_size           int(10)   NO         None                \n",
      "6    item_size_unit       varchar(20)  YES         None                \n",
      "Price_Feedback\n",
      "                 Field              Type Null  Key Default           Extra\n",
      "0    price_feedback_id  int(10) unsigned   NO  PRI    None  auto_increment\n",
      "1             store_id  int(10) unsigned  YES  MUL    None                \n",
      "2              user_id  int(10) unsigned  YES  MUL    None                \n",
      "3              item_id  int(10) unsigned  YES  MUL    None                \n",
      "4                price     decimal(10,2)   NO         None                \n",
      "5       price_currency       varchar(10)   NO         None                \n",
      "6            sale_flag        tinyint(1)   NO         None                \n",
      "7  price_feedback_text      varchar(200)  YES         None                \n",
      "8           time_added          datetime   NO         None                \n",
      "Price_Response\n",
      "                 Field              Type Null  Key Default           Extra\n",
      "0    price_response_id  int(10) unsigned   NO  PRI    None  auto_increment\n",
      "1    price_feedback_id  int(10) unsigned  YES  MUL    None                \n",
      "2     response_user_id  int(10) unsigned  YES  MUL    None                \n",
      "3           time_added          datetime   NO         None                \n",
      "4  price_response_text      varchar(200)   NO         None                \n",
      "5  price_response_vote           int(10)  YES         None                \n",
      "Shopping_List\n",
      "                      Field              Type Null  Key Default  \\\n",
      "0          shopping_list_id  int(10) unsigned   NO  PRI    None   \n",
      "1                   user_id  int(10) unsigned  YES  MUL    None   \n",
      "2                   item_id  int(10) unsigned  YES  MUL    None   \n",
      "3                time_added          datetime   NO         None   \n",
      "4  shopping_list_history_id  int(10) unsigned  YES  MUL    None   \n",
      "5             item_quantity           int(10)   NO         None   \n",
      "\n",
      "            Extra  \n",
      "0  auto_increment  \n",
      "1                  \n",
      "2                  \n",
      "3                  \n",
      "4                  \n",
      "5                  \n",
      "Shopping_List_History\n",
      "                      Field              Type Null  Key Default  \\\n",
      "0  shopping_list_history_id  int(10) unsigned   NO  PRI    None   \n",
      "1                   user_id  int(10) unsigned  YES  MUL    None   \n",
      "2                   item_id  int(10) unsigned  YES  MUL    None   \n",
      "3                time_added          datetime   NO         None   \n",
      "4              time_removed          datetime  YES         None   \n",
      "\n",
      "            Extra  \n",
      "0  auto_increment  \n",
      "1                  \n",
      "2                  \n",
      "3                  \n",
      "4                  \n",
      "State\n",
      "        Field              Type Null  Key Default           Extra\n",
      "0    state_id  int(10) unsigned   NO  PRI    None  auto_increment\n",
      "1  state_name        varchar(2)   NO         None                \n",
      "Store\n",
      "               Field              Type Null  Key Default           Extra\n",
      "0           store_id  int(10) unsigned   NO  PRI    None  auto_increment\n",
      "1         store_name       varchar(50)   NO         None                \n",
      "2          store_lat     decimal(10,8)   NO         None                \n",
      "3         store_long     decimal(11,8)   NO         None                \n",
      "4  store_active_flag        tinyint(1)   NO         None                \n",
      "5       store_street       varchar(50)  YES         None                \n",
      "6         store_city       varchar(50)  YES         None                \n",
      "7        store_state  int(10) unsigned  YES  MUL    None                \n",
      "8          store_zip       varchar(10)  YES         None                \n",
      "Store_Feedback\n",
      "                        Field              Type Null  Key Default  \\\n",
      "0           store_feedback_id  int(10) unsigned   NO  PRI    None   \n",
      "1                    store_id  int(10) unsigned  YES  MUL    None   \n",
      "2                     user_id  int(10) unsigned  YES  MUL    None   \n",
      "3                  time_added          datetime   NO         None   \n",
      "4         store_feedback_text      varchar(200)  YES         None   \n",
      "5  store_feedback_category_id  int(10) unsigned  YES  MUL    None   \n",
      "\n",
      "            Extra  \n",
      "0  auto_increment  \n",
      "1                  \n",
      "2                  \n",
      "3                  \n",
      "4                  \n",
      "5                  \n",
      "Store_Feedback_Category\n",
      "                        Field              Type Null  Key Default  \\\n",
      "0  store_feedback_category_id  int(10) unsigned   NO  PRI    None   \n",
      "1     store_feedback_category       varchar(50)   NO         None   \n",
      "\n",
      "            Extra  \n",
      "0  auto_increment  \n",
      "1                  \n",
      "Store_Response\n",
      "                 Field              Type Null  Key Default           Extra\n",
      "0    store_response_id  int(10) unsigned   NO  PRI    None  auto_increment\n",
      "1    store_feedback_id  int(10) unsigned  YES  MUL    None                \n",
      "2     response_user_id  int(10) unsigned  YES  MUL    None                \n",
      "3           time_added          datetime   NO         None                \n",
      "4  store_response_text      varchar(200)   NO         None                \n",
      "5  store_response_vote           int(10)  YES         None                \n",
      "User\n",
      "          Field              Type Null  Key Default           Extra\n",
      "0       user_id  int(10) unsigned   NO  PRI    None  auto_increment\n",
      "1    first_name       varchar(50)   NO         None                \n",
      "2     last_name       varchar(50)   NO         None                \n",
      "3         email      varchar(320)   NO         None                \n",
      "4   signup_date              date   NO         None                \n",
      "5    last_login          datetime   NO         None                \n",
      "6  user_country  int(10) unsigned  YES  MUL    None                \n",
      "User_Reputation\n",
      "                         Field              Type Null  Key Default  \\\n",
      "0           user_reputation_id  int(10) unsigned   NO  PRI    None   \n",
      "1                      user_id  int(10) unsigned  YES  MUL    None   \n",
      "2              user_reputation           int(10)   NO         None   \n",
      "3  user_reputation_category_id  int(10) unsigned  YES  MUL    None   \n",
      "4        user_received_upvotes  int(20) unsigned   NO         None   \n",
      "5      user_received_downvotes  int(20) unsigned   NO         None   \n",
      "6            user_received_net           int(10)   NO         None   \n",
      "7           user_given_upvotes  int(20) unsigned   NO         None   \n",
      "8         user_given_downvotes  int(20) unsigned   NO         None   \n",
      "9               user_given_net           int(10)   NO         None   \n",
      "\n",
      "            Extra  \n",
      "0  auto_increment  \n",
      "1                  \n",
      "2                  \n",
      "3                  \n",
      "4                  \n",
      "5                  \n",
      "6                  \n",
      "7                  \n",
      "8                  \n",
      "9                  \n",
      "User_Reputation_Category\n",
      "                           Field              Type Null  Key Default  \\\n",
      "0    user_reputation_category_id  int(10) unsigned   NO  PRI    None   \n",
      "1  user_reputation_category_name       varchar(50)   NO         None   \n",
      "\n",
      "            Extra  \n",
      "0  auto_increment  \n",
      "1                  \n"
     ]
    }
   ],
   "source": [
    "all_tables = pd.read_sql('SHOW TABLES', con=db_connection)\n",
    "print(all_tables)\n",
    "\n",
    "# Describe all the DB tables\n",
    "def describe_table(table, db_connection):\n",
    "        \n",
    "    print(table)    \n",
    "    table_cols = pd.read_sql('DESCRIBE ' + table, con=db_connection)\n",
    "    print(table_cols)\n",
    "\n",
    "result = [describe_table(table, db_connection) for table in all_tables['Tables_in_project']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load data from a CSV into MySQL database\n",
    "def data_loader_csv(data_path, table_name, db_connection, load_type):\n",
    "    \n",
    "    print(\"Loading data from CSV\")\n",
    "    \n",
    "    # Read in from CSV\n",
    "    df = pd.read_csv(data_path + 'Input Data - ' + table_name.lower() + '.csv')\n",
    "    \n",
    "    print(df.head(5))\n",
    "    \n",
    "    # Load to mySQL\n",
    "    df.to_sql(table_name, con = db_connection, if_exists = load_type, index = False)\n",
    "    \n",
    "    # Check table\n",
    "    results_df = pd.read_sql('SELECT * FROM ' + table_name + ' LIMIT 5', con=db_connection)\n",
    "    print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from CSV\n",
      "     country_name\n",
      "0     Afghanistan\n",
      "1         Albania\n",
      "2         Algeria\n",
      "3  American Samoa\n",
      "4         Andorra\n",
      "   country_id    country_name\n",
      "0           8     Afghanistan\n",
      "1           9         Albania\n",
      "2          10         Algeria\n",
      "3          11  American Samoa\n",
      "4          12         Andorra\n"
     ]
    }
   ],
   "source": [
    "data_loader_csv(data_path, \"Country\", db_connection, \"append\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from CSV\n",
      "  state_name\n",
      "0         AL\n",
      "1         AK\n",
      "2         AZ\n",
      "3         AR\n",
      "4         CA\n",
      "   state_id state_name\n",
      "0         1         AL\n",
      "1         2         AK\n",
      "2         3         AZ\n",
      "3         4         AR\n",
      "4         5         CA\n"
     ]
    }
   ],
   "source": [
    "data_loader_csv(data_path, \"State\", db_connection, \"append\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader_csv(data_path, \"Item\", db_connection, \"append\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from CSV\n",
      "  first_name last_name                              email signup_date  \\\n",
      "0       Adam    Walker       adamwalker@notarealemail.com  2020-04-20   \n",
      "1      James      Dean        jamesdean@notarealemail.com  2020-04-20   \n",
      "2    Zackary     Morse     zackarymorse@notarealemail.com  2020-04-20   \n",
      "3  Heriberto    Mellor  heribertomellor@notarealemail.com  2020-04-20   \n",
      "4      Elton    Bussey      eltonbussey@notarealemail.com  2020-04-20   \n",
      "\n",
      "   last_login  user_country  \n",
      "0  2020-04-20           235  \n",
      "1  2020-04-20           235  \n",
      "2  2020-04-20           235  \n",
      "3  2020-04-20           235  \n",
      "4  2020-04-20           235  \n",
      "   user_id first_name last_name                              email  \\\n",
      "0        1       Adam    Walker       adamwalker@notarealemail.com   \n",
      "1        2      James      Dean        jamesdean@notarealemail.com   \n",
      "2        3    Zackary     Morse     zackarymorse@notarealemail.com   \n",
      "3        4  Heriberto    Mellor  heribertomellor@notarealemail.com   \n",
      "4        5      Elton    Bussey      eltonbussey@notarealemail.com   \n",
      "\n",
      "  signup_date last_login  user_country  \n",
      "0  2020-04-20 2020-04-20           235  \n",
      "1  2020-04-20 2020-04-20           235  \n",
      "2  2020-04-20 2020-04-20           235  \n",
      "3  2020-04-20 2020-04-20           235  \n",
      "4  2020-04-20 2020-04-20           235  \n"
     ]
    }
   ],
   "source": [
    "data_loader_csv(data_path, \"User\", db_connection, \"append\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from CSV\n",
      "     store_name  store_lat  store_long  store_active_flag  \\\n",
      "0  Trader Joe's          0           0                  1   \n",
      "1  Trader Joe's          0           0                  1   \n",
      "2  Trader Joe's          0           0                  1   \n",
      "3  Trader Joe's          0           0                  1   \n",
      "4  Trader Joe's          0           0                  1   \n",
      "\n",
      "          store_street           store_city  store_state  store_zip  \n",
      "0  417 Westlake Center            Daly City            5      94015  \n",
      "1   301 McLellan Drive  South San Francisco            5      94080  \n",
      "2       265 Winston Dr        San Francisco            5      94132  \n",
      "3           401 Bay St        San Francisco            5      94133  \n",
      "4        3 Masonic Ave        San Francisco            5      94118  \n",
      "   store_id    store_name  store_lat  store_long  store_active_flag  \\\n",
      "0        67  Trader Joe's        0.0         0.0                  1   \n",
      "1        68  Trader Joe's        0.0         0.0                  1   \n",
      "2        69  Trader Joe's        0.0         0.0                  1   \n",
      "3        70  Trader Joe's        0.0         0.0                  1   \n",
      "4        71  Trader Joe's        0.0         0.0                  1   \n",
      "\n",
      "          store_street           store_city  store_state store_zip  \n",
      "0  417 Westlake Center            Daly City            5     94015  \n",
      "1   301 McLellan Drive  South San Francisco            5     94080  \n",
      "2       265 Winston Dr        San Francisco            5     94132  \n",
      "3           401 Bay St        San Francisco            5     94133  \n",
      "4        3 Masonic Ave        San Francisco            5     94118  \n"
     ]
    }
   ],
   "source": [
    "data_loader_csv(data_path, \"Store\", db_connection, \"append\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from CSV\n",
      "  store_feedback_category\n",
      "0           Out of Stocks\n",
      "1                 Pricing\n",
      "2          Rate Your Trip\n",
      "3                Cashiers\n",
      "4                 Hygiene\n",
      "   store_feedback_category_id store_feedback_category\n",
      "0                           1           Out of Stocks\n",
      "1                           2                 Pricing\n",
      "2                           3          Rate Your Trip\n",
      "3                           4                Cashiers\n",
      "4                           5                 Hygiene\n"
     ]
    }
   ],
   "source": [
    "data_loader_csv(data_path, \"Store_Feedback_Category\", db_connection, \"append\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnx = mysql.connector.connect(user='root', password='cs467project',\n",
    "                              host='localhost',\n",
    "                              database='romanesco',\n",
    "                              use_pure=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_sql('DELETE FROM Store', con=db_connection)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Field              Type Null  Key Default           Extra\n",
      "0    country_id  int(10) unsigned   NO  PRI    None  auto_increment\n",
      "1  country_name       varchar(50)   NO         None                \n"
     ]
    }
   ],
   "source": [
    "df = pd.read_sql('DESCRIBE Country', con=db_connection)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_sql('SELECT * FROM Country', con=db_connection)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_hastie_10_2\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_hastie_10_2(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.45427351,  0.76103773,  0.12167502,  0.44386323,  0.33367433,\n",
       "         1.49407907, -0.20515826,  0.3130677 , -0.85409574],\n",
       "       [ 0.6536186 ,  0.8644362 , -0.74216502,  2.26975462, -1.45436567,\n",
       "         0.04575852, -0.18718385,  1.53277921,  1.46935877],\n",
       "       [ 0.37816252, -0.88778575, -1.98079647, -0.34791215,  0.15634897,\n",
       "         1.23029068,  1.20237985, -0.38732682, -0.30230275],\n",
       "       [-1.42001794, -1.70627019,  1.9507754 , -0.50965218, -0.4380743 ,\n",
       "        -1.25279536,  0.77749036, -1.61389785, -0.21274028],\n",
       "       [ 0.3869025 , -0.51080514, -1.18063218, -0.02818223,  0.42833187,\n",
       "         0.06651722,  0.3024719 , -0.63432209, -0.36274117],\n",
       "       [-0.35955316, -0.81314628, -1.7262826 ,  0.17742614, -0.40178094,\n",
       "        -1.63019835,  0.46278226, -0.90729836,  0.0519454 ],\n",
       "       [ 0.12898291,  1.13940068, -1.23482582,  0.40234164, -0.68481009,\n",
       "        -0.87079715, -0.57884966, -0.31155253,  0.05616534],\n",
       "       [ 0.90082649,  0.46566244, -1.53624369,  1.48825219,  1.89588918,\n",
       "         1.17877957, -0.17992484, -1.07075262,  1.05445173],\n",
       "       [ 1.22244507,  0.20827498,  0.97663904,  0.3563664 ,  0.70657317,\n",
       "         0.01050002,  1.78587049,  0.12691209,  0.40198936]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[1:10,1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = X[:2000], X[2000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train, y_test = y[:2000], y[2000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0,max_depth=1, random_state=0).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.913"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create and upload a shopping list for a given user_id\n",
    "# min_items and max_items limit number of items in list\n",
    "def _fill_list(user_id, min_items, max_items, items):\n",
    "    \n",
    "    # Determine total items in list\n",
    "    tot_items = np.random.uniform(min_items, max_items, 1).round().astype(int)\n",
    "    print(tot_items)\n",
    "\n",
    "    # Get item IDs\n",
    "    list_items = np.random.choice(items['item_id'], tot_items, replace=False)\n",
    "\n",
    "    # Convert to pandas dataframe\n",
    "    dataset = pd.DataFrame({'item_id': list_items})\n",
    "\n",
    "    # Format dataframe\n",
    "    dataset['user_id'] = user_id\n",
    "    dataset['time_added'] = datetime.datetime.now()\n",
    "    dataset['time_removed'] = None\n",
    "    dataset = dataset[['user_id', 'item_id','time_added','time_removed']]\n",
    "\n",
    "    # Load to mySQL\n",
    "    print(\"Loading\")\n",
    "    dataset.to_sql('Shopping_List_History', con = db_connection, if_exists = \"append\", index = False)\n",
    "\n",
    "# Generate shopping list by sampling from items table\n",
    "def generate_shopping_list_history(db_connection, min_items, max_items):\n",
    "    \n",
    "    # Get items\n",
    "    items = pd.read_sql('SELECT DISTINCT item_id FROM Item', con=db_connection)\n",
    "    \n",
    "    # Users\n",
    "    users = pd.read_sql('SELECT DISTINCT user_id FROM User', con=db_connection)\n",
    "    \n",
    "    # Loop over users\n",
    "    result = [_fill_list(user_id, min_items, max_items, items) for user_id in users['user_id']]\n",
    "\n",
    "generate_shopping_list_history(db_connection, 1, 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    shopping_list_history_id  user_id  item_id          time_added  \\\n",
      "0                          7        1       52 2020-04-22 06:25:21   \n",
      "1                          8        1       10 2020-04-22 06:25:21   \n",
      "2                          9        1       27 2020-04-22 06:25:21   \n",
      "3                         10        1       42 2020-04-22 06:25:21   \n",
      "4                         11        1       33 2020-04-22 06:25:21   \n",
      "5                         12        1       15 2020-04-22 06:25:21   \n",
      "6                         13        1       31 2020-04-22 06:25:21   \n",
      "7                         14        1       17 2020-04-22 06:25:21   \n",
      "8                         15        1       43 2020-04-22 06:25:21   \n",
      "9                         16        1       22 2020-04-22 06:25:21   \n",
      "10                        17        1        7 2020-04-22 06:25:21   \n",
      "11                        18        1       14 2020-04-22 06:25:21   \n",
      "12                        19        1       35 2020-04-22 06:25:21   \n",
      "13                        20        1        5 2020-04-22 06:25:21   \n",
      "14                        21        1        3 2020-04-22 06:25:21   \n",
      "15                        22        2       53 2020-04-22 06:25:22   \n",
      "16                        23        2       45 2020-04-22 06:25:22   \n",
      "17                        24        2       34 2020-04-22 06:25:22   \n",
      "18                        25        2        4 2020-04-22 06:25:22   \n",
      "19                        26        2       21 2020-04-22 06:25:22   \n",
      "20                        27        2       22 2020-04-22 06:25:22   \n",
      "21                        28        2       31 2020-04-22 06:25:22   \n",
      "22                        29        2        5 2020-04-22 06:25:22   \n",
      "23                        30        2       46 2020-04-22 06:25:22   \n",
      "24                        31        2        3 2020-04-22 06:25:22   \n",
      "25                        32        2       15 2020-04-22 06:25:22   \n",
      "26                        33        2       52 2020-04-22 06:25:22   \n",
      "27                        34        2       39 2020-04-22 06:25:22   \n",
      "28                        35        2       25 2020-04-22 06:25:22   \n",
      "29                        36        2       51 2020-04-22 06:25:22   \n",
      "..                       ...      ...      ...                 ...   \n",
      "70                        77        3       30 2020-04-22 06:25:22   \n",
      "71                        78        3       32 2020-04-22 06:25:22   \n",
      "72                        79        3       23 2020-04-22 06:25:22   \n",
      "73                        80        3       10 2020-04-22 06:25:22   \n",
      "74                        81        3        8 2020-04-22 06:25:22   \n",
      "75                        82        3       34 2020-04-22 06:25:22   \n",
      "76                        83        3       17 2020-04-22 06:25:22   \n",
      "77                        84        3       55 2020-04-22 06:25:22   \n",
      "78                        85        3       43 2020-04-22 06:25:22   \n",
      "79                        86        3       38 2020-04-22 06:25:22   \n",
      "80                        87        3       19 2020-04-22 06:25:22   \n",
      "81                        88        3        6 2020-04-22 06:25:22   \n",
      "82                        89        3       28 2020-04-22 06:25:22   \n",
      "83                        90        3        3 2020-04-22 06:25:22   \n",
      "84                        91        4       34 2020-04-22 06:25:23   \n",
      "85                        92        4        9 2020-04-22 06:25:23   \n",
      "86                        93        4       53 2020-04-22 06:25:23   \n",
      "87                        94        4       13 2020-04-22 06:25:23   \n",
      "88                        95        4       11 2020-04-22 06:25:23   \n",
      "89                        96        4        6 2020-04-22 06:25:23   \n",
      "90                        97        4        2 2020-04-22 06:25:23   \n",
      "91                        98        4       41 2020-04-22 06:25:23   \n",
      "92                        99        4       38 2020-04-22 06:25:23   \n",
      "93                       100        4       55 2020-04-22 06:25:23   \n",
      "94                       101        4       39 2020-04-22 06:25:23   \n",
      "95                       102        4       29 2020-04-22 06:25:23   \n",
      "96                       103        5       36 2020-04-22 06:25:23   \n",
      "97                       104        5       39 2020-04-22 06:25:23   \n",
      "98                       105        5       21 2020-04-22 06:25:23   \n",
      "99                       106        5       52 2020-04-22 06:25:23   \n",
      "\n",
      "   time_removed  \n",
      "0          None  \n",
      "1          None  \n",
      "2          None  \n",
      "3          None  \n",
      "4          None  \n",
      "5          None  \n",
      "6          None  \n",
      "7          None  \n",
      "8          None  \n",
      "9          None  \n",
      "10         None  \n",
      "11         None  \n",
      "12         None  \n",
      "13         None  \n",
      "14         None  \n",
      "15         None  \n",
      "16         None  \n",
      "17         None  \n",
      "18         None  \n",
      "19         None  \n",
      "20         None  \n",
      "21         None  \n",
      "22         None  \n",
      "23         None  \n",
      "24         None  \n",
      "25         None  \n",
      "26         None  \n",
      "27         None  \n",
      "28         None  \n",
      "29         None  \n",
      "..          ...  \n",
      "70         None  \n",
      "71         None  \n",
      "72         None  \n",
      "73         None  \n",
      "74         None  \n",
      "75         None  \n",
      "76         None  \n",
      "77         None  \n",
      "78         None  \n",
      "79         None  \n",
      "80         None  \n",
      "81         None  \n",
      "82         None  \n",
      "83         None  \n",
      "84         None  \n",
      "85         None  \n",
      "86         None  \n",
      "87         None  \n",
      "88         None  \n",
      "89         None  \n",
      "90         None  \n",
      "91         None  \n",
      "92         None  \n",
      "93         None  \n",
      "94         None  \n",
      "95         None  \n",
      "96         None  \n",
      "97         None  \n",
      "98         None  \n",
      "99         None  \n",
      "\n",
      "[100 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# Check result\n",
    "df = pd.read_sql('SELECT * FROM Shopping_List_History LIMIT 100', con=db_connection)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate a trip\n",
    "\n",
    "# Assign a user to a preferred store\n",
    "\n",
    "# May need to shuffle shopping list\n",
    "\n",
    "# Accuracy of feedback\n",
    "\n",
    "# Need to simulate over time\n",
    "\n",
    "# Most feedback will be bad\n",
    "# Pick a feedback category\n",
    "# Assign upvote or downvote\n",
    "# Assign a likelihood of giving feedback?\n",
    "\n",
    "# Store quality, by sections?\n",
    "# Store experience vs store selection vs prices\n",
    "\n",
    "# Daily promotion dynamics\n",
    "\n",
    "# Finish with Rate Your Trip\n",
    "# Need to update store feedback categories\n",
    "\n",
    "\n",
    "# Need an update shopping list function\n",
    "# Needs to be able to load shopping list data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assigning store quality\n",
      "           store_name  chain_quality  chain_price_level  chain_stock_level\n",
      "0        Trader Joe's           0.70                0.6                0.4\n",
      "1             Safeway           0.25                0.3                0.6\n",
      "2  Whole Foods Market           0.80                0.8                0.4\n",
      "3              Costco           0.55                0.3                0.8\n",
      "     store_name  store_id  chain_quality  chain_price_level  \\\n",
      "0  Trader Joe's        67            0.7                0.6   \n",
      "1  Trader Joe's        68            0.7                0.6   \n",
      "2  Trader Joe's        69            0.7                0.6   \n",
      "3  Trader Joe's        70            0.7                0.6   \n",
      "4  Trader Joe's        71            0.7                0.6   \n",
      "\n",
      "   chain_stock_level  store_quality  store_price_level  store_stock_level  \n",
      "0                0.4       0.725095           0.676175           0.323464  \n",
      "1                0.4       0.785057           0.618761           0.415280  \n",
      "2                0.4       0.650583           0.612941           0.355643  \n",
      "3                0.4       0.693068           0.578280           0.386609  \n",
      "4                0.4       0.683921           0.653279           0.333984  \n"
     ]
    }
   ],
   "source": [
    "# ASSIGN STORE QUALITY\n",
    "\n",
    "# Gives each store a quality, randomly distributed around a chain average\n",
    "# Overall quality, price level, out of stock level\n",
    "def assign_store_quality(db_connection):\n",
    "    \n",
    "    print(\"Assigning store quality\")\n",
    "\n",
    "    # Get distinct chains\n",
    "    chains = pd.read_sql('SELECT DISTINCT store_name FROM Store', con=db_connection)\n",
    "\n",
    "    # Assign overall chain quality\n",
    "    # Higher is better\n",
    "    chains['chain_quality'] = 0.5\n",
    "    chains.loc[chains['store_name'] == \"Trader Joe's\", 'chain_quality'] = 0.7\n",
    "    chains.loc[chains['store_name'] == \"Safeway\", 'chain_quality'] = 0.25\n",
    "    chains.loc[chains['store_name'] == \"Whole Foods Market\", 'chain_quality'] = 0.8\n",
    "    chains.loc[chains['store_name'] == \"Costco\", 'chain_quality'] = 0.55\n",
    "\n",
    "    # Assign chain price level\n",
    "    # Higher means more expensive\n",
    "    chains['chain_price_level'] = 0.5\n",
    "    chains.loc[chains['store_name'] == \"Trader Joe's\", 'chain_price_level'] = 0.6\n",
    "    chains.loc[chains['store_name'] == \"Safeway\", 'chain_price_level'] = 0.3\n",
    "    chains.loc[chains['store_name'] == \"Whole Foods Market\", 'chain_price_level'] = 0.8\n",
    "    chains.loc[chains['store_name'] == \"Costco\", 'chain_price_level'] = 0.3\n",
    "\n",
    "    # Assign out of stock level\n",
    "    # Higher means more likely to have in-stock\n",
    "    chains['chain_stock_level'] = 0.5\n",
    "    chains.loc[chains['store_name'] == \"Trader Joe's\", 'chain_stock_level'] = 0.4\n",
    "    chains.loc[chains['store_name'] == \"Safeway\", 'chain_stock_level'] = 0.6\n",
    "    chains.loc[chains['store_name'] == \"Whole Foods Market\", 'chain_stock_level'] = 0.4\n",
    "    chains.loc[chains['store_name'] == \"Costco\", 'chain_stock_level'] = 0.8\n",
    "    \n",
    "    print(chains.head())\n",
    "    \n",
    "    # Get individual stores\n",
    "    stores = pd.read_sql('SELECT DISTINCT store_name, store_id FROM Store', con=db_connection)\n",
    "\n",
    "    # Join on\n",
    "    stores = stores.join(chains.set_index('store_name'), on='store_name')\n",
    "    \n",
    "    # Randomly move individual store attributes around overalll chain ones\n",
    "    stores['store_quality'] = stores['chain_quality'] + np.random.normal(0, 0.05, stores.shape[0])\n",
    "    stores['store_price_level'] = stores['chain_price_level'] + np.random.normal(0, 0.05, stores.shape[0])\n",
    "    stores['store_stock_level'] = stores['chain_stock_level'] + np.random.normal(0, 0.05, stores.shape[0])\n",
    "    \n",
    "    print(stores.head())\n",
    "    \n",
    "    return(stores)\n",
    "\n",
    "stores = assign_store_quality(db_connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_item_prices(db_connection):\n",
    "    \n",
    "    print(\"Assigning store quality\")\n",
    "\n",
    "    # Get distinct chains\n",
    "    chains = pd.read_sql('SELECT DISTINCT store_name FROM Store', con=db_connection)\n",
    "\n",
    "    # Assign overall chain quality\n",
    "    # Higher is better\n",
    "    chains['chain_quality'] = 0.5\n",
    "    chains.loc[chains['store_name'] == \"Trader Joe's\", 'chain_quality'] = 0.7\n",
    "    chains.loc[chains['store_name'] == \"Safeway\", 'chain_quality'] = 0.25\n",
    "    chains.loc[chains['store_name'] == \"Whole Foods Market\", 'chain_quality'] = 0.8\n",
    "    chains.loc[chains['store_name'] == \"Costco\", 'chain_quality'] = 0.55\n",
    "\n",
    "    # Assign chain price level\n",
    "    # Higher means more expensive\n",
    "    chains['chain_price_level'] = 0.5\n",
    "    chains.loc[chains['store_name'] == \"Trader Joe's\", 'chain_price_level'] = 0.6\n",
    "    chains.loc[chains['store_name'] == \"Safeway\", 'chain_price_level'] = 0.3\n",
    "    chains.loc[chains['store_name'] == \"Whole Foods Market\", 'chain_price_level'] = 0.8\n",
    "    chains.loc[chains['store_name'] == \"Costco\", 'chain_price_level'] = 0.3\n",
    "\n",
    "    # Assign out of stock level\n",
    "    # Higher means more likely to have in-stock\n",
    "    chains['chain_stock_level'] = 0.5\n",
    "    chains.loc[chains['store_name'] == \"Trader Joe's\", 'chain_stock_level'] = 0.4\n",
    "    chains.loc[chains['store_name'] == \"Safeway\", 'chain_stock_level'] = 0.6\n",
    "    chains.loc[chains['store_name'] == \"Whole Foods Market\", 'chain_stock_level'] = 0.4\n",
    "    chains.loc[chains['store_name'] == \"Costco\", 'chain_stock_level'] = 0.8\n",
    "    \n",
    "    print(chains.head())\n",
    "    \n",
    "    # Get individual stores\n",
    "    stores = pd.read_sql('SELECT DISTINCT store_name, store_id FROM Store', con=db_connection)\n",
    "\n",
    "    # Join on\n",
    "    stores = stores.join(chains.set_index('store_name'), on='store_name')\n",
    "    \n",
    "    # Randomly move individual store attributes around overalll chain ones\n",
    "    stores['store_quality'] = stores['chain_quality'] + np.random.normal(0, 0.05, stores.shape[0])\n",
    "    stores['store_price_level'] = stores['chain_price_level'] + np.random.normal(0, 0.05, stores.shape[0])\n",
    "    stores['store_stock_level'] = stores['chain_stock_level'] + np.random.normal(0, 0.05, stores.shape[0])\n",
    "    \n",
    "    print(stores.head())\n",
    "    \n",
    "    return(stores)\n",
    "\n",
    "stores = assign_store_quality(db_connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get store feedback categories\n",
    "store_feedback = pd.read_sql('SELECT * FROM Store_Feedback_Category', con=db_connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    store_feedback_category_id store_feedback_category\n",
      "0                            1           Out of Stocks\n",
      "1                            2                 Pricing\n",
      "2                            3          Rate Your Trip\n",
      "3                            4                Cashiers\n",
      "4                            5                 Hygiene\n",
      "5                            6                 Parking\n",
      "6                            7                 Produce\n",
      "7                            8               Selection\n",
      "8                            9                Checkout\n",
      "9                           10                Pharmacy\n",
      "10                          11             Gas Station\n",
      "11                          12                  Bakery\n",
      "12                          13                    Deli\n",
      "13                          14                 General\n",
      "14                          15                 Returns\n"
     ]
    }
   ],
   "source": [
    "print(store_feedback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_id\n",
      "0        1\n",
      "1        2\n",
      "2        3\n",
      "3        4\n",
      "4        5\n",
      "Assigning a preferred store to users\n",
      "   user_id  store_id\n",
      "0        1        77\n",
      "1        2        74\n",
      "2        3        83\n",
      "3        4        86\n",
      "4        5        80\n"
     ]
    }
   ],
   "source": [
    "# Get users\n",
    "users = pd.read_sql('SELECT DISTINCT user_id FROM User', con=db_connection)\n",
    "print(users.head())\n",
    "\n",
    "def assign_preferred_store(users, stores):\n",
    "\n",
    "    print(\"Assigning a preferred store to users\")\n",
    "    users['store_id'] = np.random.choice(stores['store_id'], users.shape[0], replace=True)\n",
    "    \n",
    "    return(users)\n",
    "    \n",
    "users = assign_preferred_store(users, stores)\n",
    "print(users.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-01-06 00:00:00\n"
     ]
    }
   ],
   "source": [
    "start_date = datetime.datetime(2020, 1, 1)\n",
    "print(start_date + timedelta(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-01-01 00:00:00\n",
      "2\n",
      "2020-01-01 00:00:00\n",
      "Taking a grocery trip!\n",
      "3\n",
      "2020-01-01 00:00:00\n",
      "Taking a grocery trip!\n",
      "4\n",
      "2020-01-01 00:00:00\n",
      "Taking a grocery trip!\n",
      "5\n",
      "2020-01-01 00:00:00\n",
      "Taking a grocery trip!\n",
      "2020-01-02 00:00:00\n",
      "2\n",
      "2020-01-12 00:00:00\n",
      "3\n",
      "2020-01-06 00:00:00\n",
      "4\n",
      "2020-01-14 00:00:00\n",
      "5\n",
      "2020-01-07 00:00:00\n",
      "2020-01-03 00:00:00\n",
      "2\n",
      "2020-01-12 00:00:00\n",
      "3\n",
      "2020-01-06 00:00:00\n",
      "4\n",
      "2020-01-14 00:00:00\n",
      "5\n",
      "2020-01-07 00:00:00\n",
      "2020-01-04 00:00:00\n",
      "2\n",
      "2020-01-12 00:00:00\n",
      "3\n",
      "2020-01-06 00:00:00\n",
      "4\n",
      "2020-01-14 00:00:00\n",
      "5\n",
      "2020-01-07 00:00:00\n",
      "2020-01-05 00:00:00\n",
      "2\n",
      "2020-01-12 00:00:00\n",
      "3\n",
      "2020-01-06 00:00:00\n",
      "4\n",
      "2020-01-14 00:00:00\n",
      "5\n",
      "2020-01-07 00:00:00\n",
      "2020-01-06 00:00:00\n",
      "2\n",
      "2020-01-12 00:00:00\n",
      "3\n",
      "2020-01-06 00:00:00\n",
      "Taking a grocery trip!\n",
      "4\n",
      "2020-01-14 00:00:00\n",
      "5\n",
      "2020-01-07 00:00:00\n",
      "2020-01-07 00:00:00\n",
      "2\n",
      "2020-01-12 00:00:00\n",
      "3\n",
      "2020-01-17 00:00:00\n",
      "4\n",
      "2020-01-14 00:00:00\n",
      "5\n",
      "2020-01-07 00:00:00\n",
      "Taking a grocery trip!\n",
      "2020-01-08 00:00:00\n",
      "2\n",
      "2020-01-12 00:00:00\n",
      "3\n",
      "2020-01-17 00:00:00\n",
      "4\n",
      "2020-01-14 00:00:00\n",
      "5\n",
      "2020-01-12 00:00:00\n",
      "2020-01-09 00:00:00\n",
      "2\n",
      "2020-01-12 00:00:00\n",
      "3\n",
      "2020-01-17 00:00:00\n",
      "4\n",
      "2020-01-14 00:00:00\n",
      "5\n",
      "2020-01-12 00:00:00\n",
      "2020-01-10 00:00:00\n",
      "2\n",
      "2020-01-12 00:00:00\n",
      "3\n",
      "2020-01-17 00:00:00\n",
      "4\n",
      "2020-01-14 00:00:00\n",
      "5\n",
      "2020-01-12 00:00:00\n",
      "2020-01-11 00:00:00\n",
      "2\n",
      "2020-01-12 00:00:00\n",
      "3\n",
      "2020-01-17 00:00:00\n",
      "4\n",
      "2020-01-14 00:00:00\n",
      "5\n",
      "2020-01-12 00:00:00\n",
      "2020-01-12 00:00:00\n",
      "2\n",
      "2020-01-12 00:00:00\n",
      "Taking a grocery trip!\n",
      "3\n",
      "2020-01-17 00:00:00\n",
      "4\n",
      "2020-01-14 00:00:00\n",
      "5\n",
      "2020-01-12 00:00:00\n",
      "Taking a grocery trip!\n",
      "2020-01-13 00:00:00\n",
      "2\n",
      "2020-01-22 00:00:00\n",
      "3\n",
      "2020-01-17 00:00:00\n",
      "4\n",
      "2020-01-14 00:00:00\n",
      "5\n",
      "2020-01-22 00:00:00\n",
      "2020-01-14 00:00:00\n",
      "2\n",
      "2020-01-22 00:00:00\n",
      "3\n",
      "2020-01-17 00:00:00\n",
      "4\n",
      "2020-01-14 00:00:00\n",
      "Taking a grocery trip!\n",
      "5\n",
      "2020-01-22 00:00:00\n",
      "2020-01-15 00:00:00\n",
      "2\n",
      "2020-01-22 00:00:00\n",
      "3\n",
      "2020-01-17 00:00:00\n",
      "4\n",
      "2020-01-22 00:00:00\n",
      "5\n",
      "2020-01-22 00:00:00\n",
      "2020-01-16 00:00:00\n",
      "2\n",
      "2020-01-22 00:00:00\n",
      "3\n",
      "2020-01-17 00:00:00\n",
      "4\n",
      "2020-01-22 00:00:00\n",
      "5\n",
      "2020-01-22 00:00:00\n",
      "2020-01-17 00:00:00\n",
      "2\n",
      "2020-01-22 00:00:00\n",
      "3\n",
      "2020-01-17 00:00:00\n",
      "Taking a grocery trip!\n",
      "4\n",
      "2020-01-22 00:00:00\n",
      "5\n",
      "2020-01-22 00:00:00\n",
      "2020-01-18 00:00:00\n",
      "2\n",
      "2020-01-22 00:00:00\n",
      "3\n",
      "2020-01-23 00:00:00\n",
      "4\n",
      "2020-01-22 00:00:00\n",
      "5\n",
      "2020-01-22 00:00:00\n",
      "2020-01-19 00:00:00\n",
      "2\n",
      "2020-01-22 00:00:00\n",
      "3\n",
      "2020-01-23 00:00:00\n",
      "4\n",
      "2020-01-22 00:00:00\n",
      "5\n",
      "2020-01-22 00:00:00\n",
      "2020-01-20 00:00:00\n",
      "2\n",
      "2020-01-22 00:00:00\n",
      "3\n",
      "2020-01-23 00:00:00\n",
      "4\n",
      "2020-01-22 00:00:00\n",
      "5\n",
      "2020-01-22 00:00:00\n",
      "2020-01-21 00:00:00\n",
      "2\n",
      "2020-01-22 00:00:00\n",
      "3\n",
      "2020-01-23 00:00:00\n",
      "4\n",
      "2020-01-22 00:00:00\n",
      "5\n",
      "2020-01-22 00:00:00\n",
      "2020-01-22 00:00:00\n",
      "2\n",
      "2020-01-22 00:00:00\n",
      "Taking a grocery trip!\n",
      "3\n",
      "2020-01-23 00:00:00\n",
      "4\n",
      "2020-01-22 00:00:00\n",
      "Taking a grocery trip!\n",
      "5\n",
      "2020-01-22 00:00:00\n",
      "Taking a grocery trip!\n",
      "2020-01-23 00:00:00\n",
      "2\n",
      "2020-01-25 00:00:00\n",
      "3\n",
      "2020-01-23 00:00:00\n",
      "Taking a grocery trip!\n",
      "4\n",
      "2020-01-29 00:00:00\n",
      "5\n",
      "2020-01-31 00:00:00\n",
      "2020-01-24 00:00:00\n",
      "2\n",
      "2020-01-25 00:00:00\n",
      "3\n",
      "2020-02-03 00:00:00\n",
      "4\n",
      "2020-01-29 00:00:00\n",
      "5\n",
      "2020-01-31 00:00:00\n",
      "2020-01-25 00:00:00\n",
      "2\n",
      "2020-01-25 00:00:00\n",
      "Taking a grocery trip!\n",
      "3\n",
      "2020-02-03 00:00:00\n",
      "4\n",
      "2020-01-29 00:00:00\n",
      "5\n",
      "2020-01-31 00:00:00\n",
      "2020-01-26 00:00:00\n",
      "2\n",
      "2020-02-01 00:00:00\n",
      "3\n",
      "2020-02-03 00:00:00\n",
      "4\n",
      "2020-01-29 00:00:00\n",
      "5\n",
      "2020-01-31 00:00:00\n",
      "2020-01-27 00:00:00\n",
      "2\n",
      "2020-02-01 00:00:00\n",
      "3\n",
      "2020-02-03 00:00:00\n",
      "4\n",
      "2020-01-29 00:00:00\n",
      "5\n",
      "2020-01-31 00:00:00\n",
      "2020-01-28 00:00:00\n",
      "2\n",
      "2020-02-01 00:00:00\n",
      "3\n",
      "2020-02-03 00:00:00\n",
      "4\n",
      "2020-01-29 00:00:00\n",
      "5\n",
      "2020-01-31 00:00:00\n",
      "2020-01-29 00:00:00\n",
      "2\n",
      "2020-02-01 00:00:00\n",
      "3\n",
      "2020-02-03 00:00:00\n",
      "4\n",
      "2020-01-29 00:00:00\n",
      "Taking a grocery trip!\n",
      "5\n",
      "2020-01-31 00:00:00\n",
      "2020-01-30 00:00:00\n",
      "2\n",
      "2020-02-01 00:00:00\n",
      "3\n",
      "2020-02-03 00:00:00\n",
      "4\n",
      "2020-02-02 00:00:00\n",
      "5\n",
      "2020-01-31 00:00:00\n",
      "2020-01-31 00:00:00\n",
      "2\n",
      "2020-02-01 00:00:00\n",
      "3\n",
      "2020-02-03 00:00:00\n",
      "4\n",
      "2020-02-02 00:00:00\n",
      "5\n",
      "2020-01-31 00:00:00\n",
      "Taking a grocery trip!\n",
      "2020-02-01 00:00:00\n",
      "2\n",
      "2020-02-01 00:00:00\n",
      "Taking a grocery trip!\n",
      "3\n",
      "2020-02-03 00:00:00\n",
      "4\n",
      "2020-02-02 00:00:00\n",
      "5\n",
      "2020-02-06 00:00:00\n",
      "2020-02-02 00:00:00\n",
      "2\n",
      "2020-02-09 00:00:00\n",
      "3\n",
      "2020-02-03 00:00:00\n",
      "4\n",
      "2020-02-02 00:00:00\n",
      "Taking a grocery trip!\n",
      "5\n",
      "2020-02-06 00:00:00\n",
      "2020-02-03 00:00:00\n",
      "2\n",
      "2020-02-09 00:00:00\n",
      "3\n",
      "2020-02-03 00:00:00\n",
      "Taking a grocery trip!\n",
      "4\n",
      "2020-02-04 00:00:00\n",
      "5\n",
      "2020-02-06 00:00:00\n",
      "2020-02-04 00:00:00\n",
      "2\n",
      "2020-02-09 00:00:00\n",
      "3\n",
      "2020-02-16 00:00:00\n",
      "4\n",
      "2020-02-04 00:00:00\n",
      "Taking a grocery trip!\n",
      "5\n",
      "2020-02-06 00:00:00\n",
      "2020-02-05 00:00:00\n",
      "2\n",
      "2020-02-09 00:00:00\n",
      "3\n",
      "2020-02-16 00:00:00\n",
      "4\n",
      "2020-02-08 00:00:00\n",
      "5\n",
      "2020-02-06 00:00:00\n",
      "2020-02-06 00:00:00\n",
      "2\n",
      "2020-02-09 00:00:00\n",
      "3\n",
      "2020-02-16 00:00:00\n",
      "4\n",
      "2020-02-08 00:00:00\n",
      "5\n",
      "2020-02-06 00:00:00\n",
      "Taking a grocery trip!\n",
      "2020-02-07 00:00:00\n",
      "2\n",
      "2020-02-09 00:00:00\n",
      "3\n",
      "2020-02-16 00:00:00\n",
      "4\n",
      "2020-02-08 00:00:00\n",
      "5\n",
      "2020-02-12 00:00:00\n",
      "2020-02-08 00:00:00\n",
      "2\n",
      "2020-02-09 00:00:00\n",
      "3\n",
      "2020-02-16 00:00:00\n",
      "4\n",
      "2020-02-08 00:00:00\n",
      "Taking a grocery trip!\n",
      "5\n",
      "2020-02-12 00:00:00\n",
      "2020-02-09 00:00:00\n",
      "2\n",
      "2020-02-09 00:00:00\n",
      "Taking a grocery trip!\n",
      "3\n",
      "2020-02-16 00:00:00\n",
      "4\n",
      "2020-02-12 00:00:00\n",
      "5\n",
      "2020-02-12 00:00:00\n",
      "2020-02-10 00:00:00\n",
      "2\n",
      "2020-02-12 00:00:00\n",
      "3\n",
      "2020-02-16 00:00:00\n",
      "4\n",
      "2020-02-12 00:00:00\n",
      "5\n",
      "2020-02-12 00:00:00\n",
      "2020-02-11 00:00:00\n",
      "2\n",
      "2020-02-12 00:00:00\n",
      "3\n",
      "2020-02-16 00:00:00\n",
      "4\n",
      "2020-02-12 00:00:00\n",
      "5\n",
      "2020-02-12 00:00:00\n",
      "2020-02-12 00:00:00\n",
      "2\n",
      "2020-02-12 00:00:00\n",
      "Taking a grocery trip!\n",
      "3\n",
      "2020-02-16 00:00:00\n",
      "4\n",
      "2020-02-12 00:00:00\n",
      "Taking a grocery trip!\n",
      "5\n",
      "2020-02-12 00:00:00\n",
      "Taking a grocery trip!\n",
      "2020-02-13 00:00:00\n",
      "2\n",
      "2020-02-17 00:00:00\n",
      "3\n",
      "2020-02-16 00:00:00\n",
      "4\n",
      "2020-02-18 00:00:00\n",
      "5\n",
      "2020-02-20 00:00:00\n",
      "2020-02-14 00:00:00\n",
      "2\n",
      "2020-02-17 00:00:00\n",
      "3\n",
      "2020-02-16 00:00:00\n",
      "4\n",
      "2020-02-18 00:00:00\n",
      "5\n",
      "2020-02-20 00:00:00\n",
      "2020-02-15 00:00:00\n",
      "2\n",
      "2020-02-17 00:00:00\n",
      "3\n",
      "2020-02-16 00:00:00\n",
      "4\n",
      "2020-02-18 00:00:00\n",
      "5\n",
      "2020-02-20 00:00:00\n",
      "2020-02-16 00:00:00\n",
      "2\n",
      "2020-02-17 00:00:00\n",
      "3\n",
      "2020-02-16 00:00:00\n",
      "Taking a grocery trip!\n",
      "4\n",
      "2020-02-18 00:00:00\n",
      "5\n",
      "2020-02-20 00:00:00\n",
      "2020-02-17 00:00:00\n",
      "2\n",
      "2020-02-17 00:00:00\n",
      "Taking a grocery trip!\n",
      "3\n",
      "2020-02-22 00:00:00\n",
      "4\n",
      "2020-02-18 00:00:00\n",
      "5\n",
      "2020-02-20 00:00:00\n",
      "2020-02-18 00:00:00\n",
      "2\n",
      "2020-02-26 00:00:00\n",
      "3\n",
      "2020-02-22 00:00:00\n",
      "4\n",
      "2020-02-18 00:00:00\n",
      "Taking a grocery trip!\n",
      "5\n",
      "2020-02-20 00:00:00\n",
      "2020-02-19 00:00:00\n",
      "2\n",
      "2020-02-26 00:00:00\n",
      "3\n",
      "2020-02-22 00:00:00\n",
      "4\n",
      "2020-02-22 00:00:00\n",
      "5\n",
      "2020-02-20 00:00:00\n",
      "2020-02-20 00:00:00\n",
      "2\n",
      "2020-02-26 00:00:00\n",
      "3\n",
      "2020-02-22 00:00:00\n",
      "4\n",
      "2020-02-22 00:00:00\n",
      "5\n",
      "2020-02-20 00:00:00\n",
      "Taking a grocery trip!\n",
      "2020-02-21 00:00:00\n",
      "2\n",
      "2020-02-26 00:00:00\n",
      "3\n",
      "2020-02-22 00:00:00\n",
      "4\n",
      "2020-02-22 00:00:00\n",
      "5\n",
      "2020-03-02 00:00:00\n",
      "2020-02-22 00:00:00\n",
      "2\n",
      "2020-02-26 00:00:00\n",
      "3\n",
      "2020-02-22 00:00:00\n",
      "Taking a grocery trip!\n",
      "4\n",
      "2020-02-22 00:00:00\n",
      "Taking a grocery trip!\n",
      "5\n",
      "2020-03-02 00:00:00\n",
      "2020-02-23 00:00:00\n",
      "2\n",
      "2020-02-26 00:00:00\n",
      "3\n",
      "2020-03-04 00:00:00\n",
      "4\n",
      "2020-02-27 00:00:00\n",
      "5\n",
      "2020-03-02 00:00:00\n",
      "2020-02-24 00:00:00\n",
      "2\n",
      "2020-02-26 00:00:00\n",
      "3\n",
      "2020-03-04 00:00:00\n",
      "4\n",
      "2020-02-27 00:00:00\n",
      "5\n",
      "2020-03-02 00:00:00\n",
      "2020-02-25 00:00:00\n",
      "2\n",
      "2020-02-26 00:00:00\n",
      "3\n",
      "2020-03-04 00:00:00\n",
      "4\n",
      "2020-02-27 00:00:00\n",
      "5\n",
      "2020-03-02 00:00:00\n",
      "2020-02-26 00:00:00\n",
      "2\n",
      "2020-02-26 00:00:00\n",
      "Taking a grocery trip!\n",
      "3\n",
      "2020-03-04 00:00:00\n",
      "4\n",
      "2020-02-27 00:00:00\n",
      "5\n",
      "2020-03-02 00:00:00\n",
      "2020-02-27 00:00:00\n",
      "2\n",
      "2020-03-09 00:00:00\n",
      "3\n",
      "2020-03-04 00:00:00\n",
      "4\n",
      "2020-02-27 00:00:00\n",
      "Taking a grocery trip!\n",
      "5\n",
      "2020-03-02 00:00:00\n",
      "2020-02-28 00:00:00\n",
      "2\n",
      "2020-03-09 00:00:00\n",
      "3\n",
      "2020-03-04 00:00:00\n",
      "4\n",
      "2020-03-06 00:00:00\n",
      "5\n",
      "2020-03-02 00:00:00\n",
      "2020-02-29 00:00:00\n",
      "2\n",
      "2020-03-09 00:00:00\n",
      "3\n",
      "2020-03-04 00:00:00\n",
      "4\n",
      "2020-03-06 00:00:00\n",
      "5\n",
      "2020-03-02 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# start_date = '2020-01-01'\n",
    "start_date = datetime.datetime(2020, 1, 1)\n",
    "users['next_trip_date'] = datetime.datetime(2020, 1, 1)\n",
    "day_count = 60\n",
    "\n",
    "def take_a_trip(sim_date, u):\n",
    "    \n",
    "    print(\"Take a trip\")\n",
    "    print(u)\n",
    "\n",
    "for sim_date in (start_date + timedelta(n) for n in range(day_count)):\n",
    "    \n",
    "    # Simulate a day\n",
    "    print(sim_date)\n",
    "    \n",
    "    # Delete shopping list data\n",
    "    # Pull new shopping list using historical data\n",
    "    \n",
    "    # Loop over users\n",
    "    for u in users['user_id'][1:5]:\n",
    "        \n",
    "        # Get date of user's next grocery trip\n",
    "        print(u)        \n",
    "        user_row = users[users['user_id'] == u]        \n",
    "        next_trip_date = user_row.iloc[0]['next_trip_date']\n",
    "        print(next_trip_date)\n",
    "        \n",
    "        # If today, have the user take a grocery trip\n",
    "        if next_trip_date == sim_date:\n",
    "            \n",
    "            print(\"Taking a grocery trip!\")\n",
    "            \n",
    "            # Update shopping list\n",
    "            \n",
    "            # Go to the store\n",
    "            \n",
    "            # Critique feedback            \n",
    "            \n",
    "            # Update date of next trip\n",
    "            # Randomly choose a value\n",
    "            days_until_next_trip = int(np.random.poisson(7, 1))\n",
    "            users.loc[users['user_id'] == u, \"next_trip_date\"] = sim_date + timedelta(days_until_next_trip)\n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1     2\n",
       "2     3\n",
       "3     4\n",
       "4     5\n",
       "5     6\n",
       "6     7\n",
       "7     8\n",
       "8     9\n",
       "9    10\n",
       "Name: user_id, dtype: int64"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users['user_id'][1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10, 12,  4,  4,  8,  7, 10,  5, 10,  8,  5, 12,  9, 11,  5,  5, 11,\n",
       "        4,  5,  4,  5, 10,  4, 13,  2,  6, 12,  4,  7,  9,  4,  9,  7,  4,\n",
       "       11,  9,  6, 10,  3,  6, 11,  5, 11,  8,  9,  9,  5,  3,  9,  9,  9,\n",
       "        7, 10,  3,  4, 17,  6, 11,  6,  4,  5,  3,  4,  8,  7,  8,  2, 10,\n",
       "        7, 10, 10,  6, 10,  7,  7,  6,  7,  4,  6,  4,  2,  6,  7,  5,  9,\n",
       "        5, 11, 10,  2,  9, 11,  1, 11,  8, 10,  4,  1,  8,  9,  9])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.poisson(7, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>store_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  store_id\n",
       "0        1        77\n",
       "1        2        74\n",
       "2        3        83\n",
       "3        4        86\n",
       "4        5        80"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Simulate a trip schedule\n",
    "\n",
    "users.head()\n",
    "\n",
    "users['last_trip_date']\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = pd.read_sql('SELECT DISTINCT item_id FROM Item', con=db_connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = pd.read_sql('SELECT DISTINCT user_id FROM User', con=db_connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe_table(table, db_connection):\n",
    "        \n",
    "    print(table)    \n",
    "    table_cols = pd.read_sql('DESCRIBE ' + table, con=db_connection)\n",
    "    print(table_cols)\n",
    "\n",
    "result = [fill_list(user_id, min_items, max_items) for user_id in users['user_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_sql('''INSERT INTO Shopping_List (user_id, item_id, time_added, shopping_list_history_id, item_quantity)\n",
    "                  SELECT \n",
    "                  user_id\n",
    "                  , item_id\n",
    "                  , time_added\n",
    "                  , shopping_list_history_id\n",
    "                  , 1 as item_quantity\n",
    "                  FROM Shopping_List_History\n",
    "                  WHERE time_removed IS NULL'''\n",
    "                 , con=db_connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      shopping_list_id  user_id  item_id          time_added  \\\n",
      "0                    1        1       52 2020-04-22 06:25:21   \n",
      "1                    2        1       10 2020-04-22 06:25:21   \n",
      "2                    3        1       27 2020-04-22 06:25:21   \n",
      "3                    4        1       42 2020-04-22 06:25:21   \n",
      "4                    5        1       33 2020-04-22 06:25:21   \n",
      "5                    6        1       15 2020-04-22 06:25:21   \n",
      "6                    7        1       31 2020-04-22 06:25:21   \n",
      "7                    8        1       17 2020-04-22 06:25:21   \n",
      "8                    9        1       43 2020-04-22 06:25:21   \n",
      "9                   10        1       22 2020-04-22 06:25:21   \n",
      "10                  11        1        7 2020-04-22 06:25:21   \n",
      "11                  12        1       14 2020-04-22 06:25:21   \n",
      "12                  13        1       35 2020-04-22 06:25:21   \n",
      "13                  14        1        5 2020-04-22 06:25:21   \n",
      "14                  15        1        3 2020-04-22 06:25:21   \n",
      "15                  16        2       53 2020-04-22 06:25:22   \n",
      "16                  17        2       45 2020-04-22 06:25:22   \n",
      "17                  18        2       34 2020-04-22 06:25:22   \n",
      "18                  19        2        4 2020-04-22 06:25:22   \n",
      "19                  20        2       21 2020-04-22 06:25:22   \n",
      "20                  21        2       22 2020-04-22 06:25:22   \n",
      "21                  22        2       31 2020-04-22 06:25:22   \n",
      "22                  23        2        5 2020-04-22 06:25:22   \n",
      "23                  24        2       46 2020-04-22 06:25:22   \n",
      "24                  25        2        3 2020-04-22 06:25:22   \n",
      "25                  26        2       15 2020-04-22 06:25:22   \n",
      "26                  27        2       52 2020-04-22 06:25:22   \n",
      "27                  28        2       39 2020-04-22 06:25:22   \n",
      "28                  29        2       25 2020-04-22 06:25:22   \n",
      "29                  30        2       51 2020-04-22 06:25:22   \n",
      "...                ...      ...      ...                 ...   \n",
      "4320              4321      201       28 2020-04-22 06:27:22   \n",
      "4321              4322      201       27 2020-04-22 06:27:22   \n",
      "4322              4323      201       51 2020-04-22 06:27:22   \n",
      "4323              4324      201       37 2020-04-22 06:27:22   \n",
      "4324              4325      201       47 2020-04-22 06:27:22   \n",
      "4325              4326      201       50 2020-04-22 06:27:22   \n",
      "4326              4327      201       39 2020-04-22 06:27:22   \n",
      "4327              4328      201       36 2020-04-22 06:27:22   \n",
      "4328              4329      201        1 2020-04-22 06:27:22   \n",
      "4329              4330      201       48 2020-04-22 06:27:22   \n",
      "4330              4331      201       44 2020-04-22 06:27:22   \n",
      "4331              4332      201       45 2020-04-22 06:27:22   \n",
      "4332              4333      201       41 2020-04-22 06:27:22   \n",
      "4333              4334      201       31 2020-04-22 06:27:22   \n",
      "4334              4335      201       29 2020-04-22 06:27:22   \n",
      "4335              4336      201        5 2020-04-22 06:27:22   \n",
      "4336              4337      201       35 2020-04-22 06:27:22   \n",
      "4337              4338      201       24 2020-04-22 06:27:22   \n",
      "4338              4339      201        6 2020-04-22 06:27:22   \n",
      "4339              4340      201        3 2020-04-22 06:27:22   \n",
      "4340              4341      202       53 2020-04-22 06:27:23   \n",
      "4341              4342      202       45 2020-04-22 06:27:23   \n",
      "4342              4343      202       19 2020-04-22 06:27:23   \n",
      "4343              4344      202       55 2020-04-22 06:27:23   \n",
      "4344              4345      202       51 2020-04-22 06:27:23   \n",
      "4345              4346      202       26 2020-04-22 06:27:23   \n",
      "4346              4347      202       37 2020-04-22 06:27:23   \n",
      "4347              4348      202       27 2020-04-22 06:27:23   \n",
      "4348              4349      202        6 2020-04-22 06:27:23   \n",
      "4349              4350      202       15 2020-04-22 06:27:23   \n",
      "\n",
      "      shopping_list_history_id  item_quantity  \n",
      "0                            7              1  \n",
      "1                            8              1  \n",
      "2                            9              1  \n",
      "3                           10              1  \n",
      "4                           11              1  \n",
      "5                           12              1  \n",
      "6                           13              1  \n",
      "7                           14              1  \n",
      "8                           15              1  \n",
      "9                           16              1  \n",
      "10                          17              1  \n",
      "11                          18              1  \n",
      "12                          19              1  \n",
      "13                          20              1  \n",
      "14                          21              1  \n",
      "15                          22              1  \n",
      "16                          23              1  \n",
      "17                          24              1  \n",
      "18                          25              1  \n",
      "19                          26              1  \n",
      "20                          27              1  \n",
      "21                          28              1  \n",
      "22                          29              1  \n",
      "23                          30              1  \n",
      "24                          31              1  \n",
      "25                          32              1  \n",
      "26                          33              1  \n",
      "27                          34              1  \n",
      "28                          35              1  \n",
      "29                          36              1  \n",
      "...                        ...            ...  \n",
      "4320                      4327              1  \n",
      "4321                      4328              1  \n",
      "4322                      4329              1  \n",
      "4323                      4330              1  \n",
      "4324                      4331              1  \n",
      "4325                      4332              1  \n",
      "4326                      4333              1  \n",
      "4327                      4334              1  \n",
      "4328                      4335              1  \n",
      "4329                      4336              1  \n",
      "4330                      4337              1  \n",
      "4331                      4338              1  \n",
      "4332                      4339              1  \n",
      "4333                      4340              1  \n",
      "4334                      4341              1  \n",
      "4335                      4342              1  \n",
      "4336                      4343              1  \n",
      "4337                      4344              1  \n",
      "4338                      4345              1  \n",
      "4339                      4346              1  \n",
      "4340                      4347              1  \n",
      "4341                      4348              1  \n",
      "4342                      4349              1  \n",
      "4343                      4350              1  \n",
      "4344                      4351              1  \n",
      "4345                      4352              1  \n",
      "4346                      4353              1  \n",
      "4347                      4354              1  \n",
      "4348                      4355              1  \n",
      "4349                      4356              1  \n",
      "\n",
      "[4350 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_sql('SELECT * FROM Shopping_List', con=db_connection)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "with db_connection.connect() as connection:\n",
    "    result = connection.execute('''DELETE FROM Shopping_List''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "with db_connection.connect() as connection:\n",
    "    result = connection.execute('''\n",
    "        INSERT INTO Shopping_List (user_id, item_id, time_added, shopping_list_history_id, item_quantity)\n",
    "        SELECT\n",
    "        user_id\n",
    "        , item_id\n",
    "        , time_added\n",
    "        , shopping_list_history_id\n",
    "        , 1 as item_quantity\n",
    "        FROM Shopping_List_History\n",
    "        WHERE time_removed IS NULL''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in result:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      shopping_list_id  user_id  item_id          time_added  \\\n",
      "0                 8192        1       52 2020-04-22 06:25:21   \n",
      "1                 8193        1       10 2020-04-22 06:25:21   \n",
      "2                 8194        1       27 2020-04-22 06:25:21   \n",
      "3                 8195        1       42 2020-04-22 06:25:21   \n",
      "4                 8196        1       33 2020-04-22 06:25:21   \n",
      "5                 8197        1       15 2020-04-22 06:25:21   \n",
      "6                 8198        1       31 2020-04-22 06:25:21   \n",
      "7                 8199        1       17 2020-04-22 06:25:21   \n",
      "8                 8200        1       43 2020-04-22 06:25:21   \n",
      "9                 8201        1       22 2020-04-22 06:25:21   \n",
      "10                8202        1        7 2020-04-22 06:25:21   \n",
      "11                8203        1       14 2020-04-22 06:25:21   \n",
      "12                8204        1       35 2020-04-22 06:25:21   \n",
      "13                8205        1        5 2020-04-22 06:25:21   \n",
      "14                8206        1        3 2020-04-22 06:25:21   \n",
      "15                8207        2       53 2020-04-22 06:25:22   \n",
      "16                8208        2       45 2020-04-22 06:25:22   \n",
      "17                8209        2       34 2020-04-22 06:25:22   \n",
      "18                8210        2        4 2020-04-22 06:25:22   \n",
      "19                8211        2       21 2020-04-22 06:25:22   \n",
      "20                8212        2       22 2020-04-22 06:25:22   \n",
      "21                8213        2       31 2020-04-22 06:25:22   \n",
      "22                8214        2        5 2020-04-22 06:25:22   \n",
      "23                8215        2       46 2020-04-22 06:25:22   \n",
      "24                8216        2        3 2020-04-22 06:25:22   \n",
      "25                8217        2       15 2020-04-22 06:25:22   \n",
      "26                8218        2       52 2020-04-22 06:25:22   \n",
      "27                8219        2       39 2020-04-22 06:25:22   \n",
      "28                8220        2       25 2020-04-22 06:25:22   \n",
      "29                8221        2       51 2020-04-22 06:25:22   \n",
      "...                ...      ...      ...                 ...   \n",
      "4320             12512      201       28 2020-04-22 06:27:22   \n",
      "4321             12513      201       27 2020-04-22 06:27:22   \n",
      "4322             12514      201       51 2020-04-22 06:27:22   \n",
      "4323             12515      201       37 2020-04-22 06:27:22   \n",
      "4324             12516      201       47 2020-04-22 06:27:22   \n",
      "4325             12517      201       50 2020-04-22 06:27:22   \n",
      "4326             12518      201       39 2020-04-22 06:27:22   \n",
      "4327             12519      201       36 2020-04-22 06:27:22   \n",
      "4328             12520      201        1 2020-04-22 06:27:22   \n",
      "4329             12521      201       48 2020-04-22 06:27:22   \n",
      "4330             12522      201       44 2020-04-22 06:27:22   \n",
      "4331             12523      201       45 2020-04-22 06:27:22   \n",
      "4332             12524      201       41 2020-04-22 06:27:22   \n",
      "4333             12525      201       31 2020-04-22 06:27:22   \n",
      "4334             12526      201       29 2020-04-22 06:27:22   \n",
      "4335             12527      201        5 2020-04-22 06:27:22   \n",
      "4336             12528      201       35 2020-04-22 06:27:22   \n",
      "4337             12529      201       24 2020-04-22 06:27:22   \n",
      "4338             12530      201        6 2020-04-22 06:27:22   \n",
      "4339             12531      201        3 2020-04-22 06:27:22   \n",
      "4340             12532      202       53 2020-04-22 06:27:23   \n",
      "4341             12533      202       45 2020-04-22 06:27:23   \n",
      "4342             12534      202       19 2020-04-22 06:27:23   \n",
      "4343             12535      202       55 2020-04-22 06:27:23   \n",
      "4344             12536      202       51 2020-04-22 06:27:23   \n",
      "4345             12537      202       26 2020-04-22 06:27:23   \n",
      "4346             12538      202       37 2020-04-22 06:27:23   \n",
      "4347             12539      202       27 2020-04-22 06:27:23   \n",
      "4348             12540      202        6 2020-04-22 06:27:23   \n",
      "4349             12541      202       15 2020-04-22 06:27:23   \n",
      "\n",
      "      shopping_list_history_id  item_quantity  \n",
      "0                            7              1  \n",
      "1                            8              1  \n",
      "2                            9              1  \n",
      "3                           10              1  \n",
      "4                           11              1  \n",
      "5                           12              1  \n",
      "6                           13              1  \n",
      "7                           14              1  \n",
      "8                           15              1  \n",
      "9                           16              1  \n",
      "10                          17              1  \n",
      "11                          18              1  \n",
      "12                          19              1  \n",
      "13                          20              1  \n",
      "14                          21              1  \n",
      "15                          22              1  \n",
      "16                          23              1  \n",
      "17                          24              1  \n",
      "18                          25              1  \n",
      "19                          26              1  \n",
      "20                          27              1  \n",
      "21                          28              1  \n",
      "22                          29              1  \n",
      "23                          30              1  \n",
      "24                          31              1  \n",
      "25                          32              1  \n",
      "26                          33              1  \n",
      "27                          34              1  \n",
      "28                          35              1  \n",
      "29                          36              1  \n",
      "...                        ...            ...  \n",
      "4320                      4327              1  \n",
      "4321                      4328              1  \n",
      "4322                      4329              1  \n",
      "4323                      4330              1  \n",
      "4324                      4331              1  \n",
      "4325                      4332              1  \n",
      "4326                      4333              1  \n",
      "4327                      4334              1  \n",
      "4328                      4335              1  \n",
      "4329                      4336              1  \n",
      "4330                      4337              1  \n",
      "4331                      4338              1  \n",
      "4332                      4339              1  \n",
      "4333                      4340              1  \n",
      "4334                      4341              1  \n",
      "4335                      4342              1  \n",
      "4336                      4343              1  \n",
      "4337                      4344              1  \n",
      "4338                      4345              1  \n",
      "4339                      4346              1  \n",
      "4340                      4347              1  \n",
      "4341                      4348              1  \n",
      "4342                      4349              1  \n",
      "4343                      4350              1  \n",
      "4344                      4351              1  \n",
      "4345                      4352              1  \n",
      "4346                      4353              1  \n",
      "4347                      4354              1  \n",
      "4348                      4355              1  \n",
      "4349                      4356              1  \n",
      "\n",
      "[4350 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_sql('SELECT * FROM Shopping_List', con=db_connection)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_sql('DELETE FROM Shopping_List_History', con=db_connection)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15]\n",
      "Loading\n",
      "[30]\n",
      "Loading\n",
      "[39]\n",
      "Loading\n",
      "[12]\n",
      "Loading\n",
      "[35]\n",
      "Loading\n",
      "[30]\n",
      "Loading\n",
      "[28]\n",
      "Loading\n",
      "[33]\n",
      "Loading\n",
      "[8]\n",
      "Loading\n",
      "[6]\n",
      "Loading\n",
      "[1]\n",
      "Loading\n",
      "[32]\n",
      "Loading\n",
      "[26]\n",
      "Loading\n",
      "[10]\n",
      "Loading\n",
      "[2]\n",
      "Loading\n",
      "[25]\n",
      "Loading\n",
      "[20]\n",
      "Loading\n",
      "[39]\n",
      "Loading\n",
      "[7]\n",
      "Loading\n",
      "[17]\n",
      "Loading\n",
      "[17]\n",
      "Loading\n",
      "[13]\n",
      "Loading\n",
      "[31]\n",
      "Loading\n",
      "[13]\n",
      "Loading\n",
      "[10]\n",
      "Loading\n",
      "[12]\n",
      "Loading\n",
      "[25]\n",
      "Loading\n",
      "[24]\n",
      "Loading\n",
      "[32]\n",
      "Loading\n",
      "[7]\n",
      "Loading\n",
      "[25]\n",
      "Loading\n",
      "[5]\n",
      "Loading\n",
      "[16]\n",
      "Loading\n",
      "[36]\n",
      "Loading\n",
      "[18]\n",
      "Loading\n",
      "[34]\n",
      "Loading\n",
      "[14]\n",
      "Loading\n",
      "[33]\n",
      "Loading\n",
      "[15]\n",
      "Loading\n",
      "[3]\n",
      "Loading\n",
      "[17]\n",
      "Loading\n",
      "[13]\n",
      "Loading\n",
      "[15]\n",
      "Loading\n",
      "[16]\n",
      "Loading\n",
      "[31]\n",
      "Loading\n",
      "[6]\n",
      "Loading\n",
      "[3]\n",
      "Loading\n",
      "[26]\n",
      "Loading\n",
      "[36]\n",
      "Loading\n",
      "[23]\n",
      "Loading\n",
      "[28]\n",
      "Loading\n",
      "[20]\n",
      "Loading\n",
      "[20]\n",
      "Loading\n",
      "[33]\n",
      "Loading\n",
      "[16]\n",
      "Loading\n",
      "[25]\n",
      "Loading\n",
      "[12]\n",
      "Loading\n",
      "[8]\n",
      "Loading\n",
      "[32]\n",
      "Loading\n",
      "[40]\n",
      "Loading\n",
      "[22]\n",
      "Loading\n",
      "[30]\n",
      "Loading\n",
      "[38]\n",
      "Loading\n",
      "[3]\n",
      "Loading\n",
      "[34]\n",
      "Loading\n",
      "[24]\n",
      "Loading\n",
      "[27]\n",
      "Loading\n",
      "[10]\n",
      "Loading\n",
      "[37]\n",
      "Loading\n",
      "[39]\n",
      "Loading\n",
      "[39]\n",
      "Loading\n",
      "[29]\n",
      "Loading\n",
      "[13]\n",
      "Loading\n",
      "[34]\n",
      "Loading\n",
      "[35]\n",
      "Loading\n",
      "[21]\n",
      "Loading\n",
      "[9]\n",
      "Loading\n",
      "[9]\n",
      "Loading\n",
      "[1]\n",
      "Loading\n",
      "[22]\n",
      "Loading\n",
      "[22]\n",
      "Loading\n",
      "[26]\n",
      "Loading\n",
      "[16]\n",
      "Loading\n",
      "[36]\n",
      "Loading\n",
      "[7]\n",
      "Loading\n",
      "[21]\n",
      "Loading\n",
      "[20]\n",
      "Loading\n",
      "[17]\n",
      "Loading\n",
      "[9]\n",
      "Loading\n",
      "[33]\n",
      "Loading\n",
      "[17]\n",
      "Loading\n",
      "[37]\n",
      "Loading\n",
      "[23]\n",
      "Loading\n",
      "[24]\n",
      "Loading\n",
      "[33]\n",
      "Loading\n",
      "[8]\n",
      "Loading\n",
      "[5]\n",
      "Loading\n",
      "[28]\n",
      "Loading\n",
      "[28]\n",
      "Loading\n",
      "[25]\n",
      "Loading\n",
      "[3]\n",
      "Loading\n",
      "[29]\n",
      "Loading\n",
      "[12]\n",
      "Loading\n",
      "[26]\n",
      "Loading\n",
      "[7]\n",
      "Loading\n",
      "[27]\n",
      "Loading\n",
      "[33]\n",
      "Loading\n",
      "[32]\n",
      "Loading\n",
      "[7]\n",
      "Loading\n",
      "[20]\n",
      "Loading\n",
      "[36]\n",
      "Loading\n",
      "[21]\n",
      "Loading\n",
      "[24]\n",
      "Loading\n",
      "[10]\n",
      "Loading\n",
      "[30]\n",
      "Loading\n",
      "[38]\n",
      "Loading\n",
      "[6]\n",
      "Loading\n",
      "[14]\n",
      "Loading\n",
      "[20]\n",
      "Loading\n",
      "[3]\n",
      "Loading\n",
      "[19]\n",
      "Loading\n",
      "[9]\n",
      "Loading\n",
      "[2]\n",
      "Loading\n",
      "[14]\n",
      "Loading\n",
      "[1]\n",
      "Loading\n",
      "[7]\n",
      "Loading\n",
      "[27]\n",
      "Loading\n",
      "[25]\n",
      "Loading\n",
      "[7]\n",
      "Loading\n",
      "[19]\n",
      "Loading\n",
      "[20]\n",
      "Loading\n",
      "[20]\n",
      "Loading\n",
      "[9]\n",
      "Loading\n",
      "[36]\n",
      "Loading\n",
      "[39]\n",
      "Loading\n",
      "[38]\n",
      "Loading\n",
      "[8]\n",
      "Loading\n",
      "[33]\n",
      "Loading\n",
      "[18]\n",
      "Loading\n",
      "[8]\n",
      "Loading\n",
      "[22]\n",
      "Loading\n",
      "[2]\n",
      "Loading\n",
      "[38]\n",
      "Loading\n",
      "[25]\n",
      "Loading\n",
      "[11]\n",
      "Loading\n",
      "[33]\n",
      "Loading\n",
      "[14]\n",
      "Loading\n",
      "[5]\n",
      "Loading\n",
      "[12]\n",
      "Loading\n",
      "[23]\n",
      "Loading\n",
      "[21]\n",
      "Loading\n",
      "[14]\n",
      "Loading\n",
      "[2]\n",
      "Loading\n",
      "[2]\n",
      "Loading\n",
      "[28]\n",
      "Loading\n",
      "[20]\n",
      "Loading\n",
      "[29]\n",
      "Loading\n",
      "[25]\n",
      "Loading\n",
      "[16]\n",
      "Loading\n",
      "[22]\n",
      "Loading\n",
      "[14]\n",
      "Loading\n",
      "[35]\n",
      "Loading\n",
      "[28]\n",
      "Loading\n",
      "[36]\n",
      "Loading\n",
      "[5]\n",
      "Loading\n",
      "[13]\n",
      "Loading\n",
      "[20]\n",
      "Loading\n",
      "[24]\n",
      "Loading\n",
      "[25]\n",
      "Loading\n",
      "[17]\n",
      "Loading\n",
      "[25]\n",
      "Loading\n",
      "[39]\n",
      "Loading\n",
      "[20]\n",
      "Loading\n",
      "[12]\n",
      "Loading\n",
      "[22]\n",
      "Loading\n",
      "[29]\n",
      "Loading\n",
      "[37]\n",
      "Loading\n",
      "[31]\n",
      "Loading\n",
      "[30]\n",
      "Loading\n",
      "[15]\n",
      "Loading\n",
      "[34]\n",
      "Loading\n",
      "[39]\n",
      "Loading\n",
      "[39]\n",
      "Loading\n",
      "[9]\n",
      "Loading\n",
      "[35]\n",
      "Loading\n",
      "[39]\n",
      "Loading\n",
      "[4]\n",
      "Loading\n",
      "[19]\n",
      "Loading\n",
      "[27]\n",
      "Loading\n",
      "[21]\n",
      "Loading\n",
      "[23]\n",
      "Loading\n",
      "[35]\n",
      "Loading\n",
      "[34]\n",
      "Loading\n",
      "[37]\n",
      "Loading\n",
      "[33]\n",
      "Loading\n",
      "[30]\n",
      "Loading\n",
      "[34]\n",
      "Loading\n",
      "[36]\n",
      "Loading\n",
      "[37]\n",
      "Loading\n",
      "[25]\n",
      "Loading\n",
      "[23]\n",
      "Loading\n",
      "[10]\n",
      "Loading\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize list of lists \n",
    "data = [['United States of America'], ['Brazil'], ['Spain']] \n",
    "  \n",
    "# Create the pandas DataFrame \n",
    "df = pd.DataFrame(data, columns = ['country_name']) \n",
    "  \n",
    "# print dataframe. \n",
    "df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
